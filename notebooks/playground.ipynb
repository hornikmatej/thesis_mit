{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import huggingface_hub\n",
    "\n",
    "# load env var huggingface token\n",
    "load_dotenv(os.path.join(\"../\", \".env\"))\n",
    "# login to the hub\n",
    "huggingface_hub.login(token=os.getenv(\"HUGGINGFACE_TOKEN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "\n",
    "voxpopuli = datasets.load_dataset(\"facebook/voxpopuli\", \"en\", streaming=True, trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'audio_id': '20180418-0900-PLENARY-3-en_20180418-08:50:36_17', 'language': 0, 'audio': {'path': 'train_part_0/20180418-0900-PLENARY-3-en_20180418-08:50:36_17.wav', 'array': array([-0.00030518,  0.00119019,  0.00506592, ..., -0.00036621,\n",
      "       -0.00027466, -0.00018311]), 'sampling_rate': 16000}, 'raw_text': 'If you do not address this problem, the ground is there for populist nationalist forces to go on growing all over Europe.', 'normalized_text': 'if you do not address this problem the ground is there for populist nationalist forces to go on growing all over europe.', 'gender': 'female', 'speaker_id': '124737', 'is_gold_transcript': True, 'accent': 'None'}, {'audio_id': '20170614-0900-PLENARY-5-en_20170614-10:03:08_5', 'language': 0, 'audio': {'path': 'train_part_0/20170614-0900-PLENARY-5-en_20170614-10:03:08_5.wav', 'array': array([-0.00036621, -0.00030518, -0.00042725, ...,  0.00012207,\n",
      "        0.00119019,  0.00027466]), 'sampling_rate': 16000}, 'raw_text': 'they attacked and removed the voices of resistance from our radio and TV stations. They attack and abuse the President who was elected in the United States of America, yet celebrate the globalist placeman they installed in France.', 'normalized_text': 'they attacked and removed the voices of resistance from our radio and tv stations. they attack and abuse the president who was elected in the united states of america yet celebrate the globalist placeman they installed in france.', 'gender': 'male', 'speaker_id': '124966', 'is_gold_transcript': True, 'accent': 'None'}, {'audio_id': '20180314-0900-PLENARY-13-en_20180314-16:03:18_3', 'language': 0, 'audio': {'path': 'train_part_0/20180314-0900-PLENARY-13-en_20180314-16:03:18_3.wav', 'array': array([ 0.00201416, -0.00344849, -0.00460815, ...,  0.00076294,\n",
      "        0.00198364,  0.0012207 ]), 'sampling_rate': 16000}, 'raw_text': 'In order to increase the preparedness at national and EU level, the key word to overcome those challenges is cooperation and the multidimensional aspects public private cooperation, cooperation between Member States, economic cross border and cross sector collaboration,', 'normalized_text': 'in order to increase the preparedness at national and eu level the key word to overcome those challenges is cooperation and the multidimensional aspects public private cooperation cooperation between member states economic cross border and cross sector collaboration', 'gender': 'female', 'speaker_id': 'None', 'is_gold_transcript': True, 'accent': 'None'}, {'audio_id': '20160413-0900-PLENARY-17-en_20160413-15:33:39_4', 'language': 0, 'audio': {'path': 'train_part_0/20160413-0900-PLENARY-17-en_20160413-15:33:39_4.wav', 'array': array([-0.00012207, -0.00048828,  0.        , ..., -0.0007019 ,\n",
      "        0.00045776,  0.00128174]), 'sampling_rate': 16000}, 'raw_text': 'These are not easy issues to resolve.', 'normalized_text': 'these are not easy issues to resolve.', 'gender': 'male', 'speaker_id': '28497', 'is_gold_transcript': True, 'accent': 'None'}, {'audio_id': '20170215-0900-PLENARY-4-en_20170215-10:17:28_5', 'language': 0, 'audio': {'path': 'train_part_0/20170215-0900-PLENARY-4-en_20170215-10:17:28_5.wav', 'array': array([ 0.00259399,  0.00048828, -0.00491333, ...,  0.05822754,\n",
      "        0.0586853 ,  0.05407715]), 'sampling_rate': 16000}, 'raw_text': 'So it is a good deal.', 'normalized_text': 'so it is a good deal.', 'gender': 'male', 'speaker_id': '96912', 'is_gold_transcript': True, 'accent': 'None'}]\n"
     ]
    }
   ],
   "source": [
    "voxpopuli_head = list(voxpopuli[\"train\"].take(5))\n",
    "SAMPLING_RATE = voxpopuli_head[0][\"audio\"][\"sampling_rate\"]\n",
    "print(voxpopuli_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoFeatureExtractor,\n",
    "    SpeechEncoderDecoderModel,\n",
    "    SpeechEncoderDecoderConfig,\n",
    "    AutoConfig,\n",
    ")\n",
    "\n",
    "import torch\n",
    "\n",
    "encoder_id = \"facebook/wav2vec2-base-960h\"  # acoustic model encoder\n",
    "decoder_id = \"facebook/bart-base\"  # text decoder\n",
    "\n",
    "# feature_extractor = AutoFeatureExtractor.from_pretrained(encoder_id)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(decoder_id)\n",
    "\n",
    "model = SpeechEncoderDecoderModel.from_encoder_decoder_pretrained(\n",
    "    encoder_id, decoder_id, encoder_add_adapter=True\n",
    ")\n",
    "model.config.encoder.feat_proj_dropout = 0.0\n",
    "model.config.encoder.mask_time_prob = 0.0\n",
    "model.config.decoder_start_token_id = model.decoder.config.bos_token_id\n",
    "model.config.pad_token_id = model.decoder.config.pad_token_id\n",
    "model.config.eos_token_id = model.decoder.config.eos_token_id\n",
    "model.config.max_length = 128\n",
    "model.config.encoder.layerdrop = 0.0\n",
    "model.config.use_cache = False\n",
    "model.config.processor_class = \"Wav2Vec2Processor\"\n",
    "\n",
    "# Load model without pretrained weights\n",
    "config_encoder = AutoConfig.from_pretrained(encoder_id)\n",
    "config_encoder.add_adapter = True\n",
    "config_decoder = AutoConfig.from_pretrained(decoder_id)\n",
    "config_decoder.is_decoder = True\n",
    "config_decoder.add_cross_attention = True\n",
    "\n",
    "config = SpeechEncoderDecoderConfig.from_encoder_decoder_configs(\n",
    "    config_encoder, config_decoder\n",
    ")\n",
    "model_no_weights = SpeechEncoderDecoderModel(config=config)\n",
    "\n",
    "model_no_weights.config.encoder.feat_proj_dropout = 0.0\n",
    "model_no_weights.config.encoder.mask_time_prob = 0.0\n",
    "model_no_weights.config.decoder_start_token_id = model_no_weights.decoder.config.bos_token_id\n",
    "model_no_weights.config.pad_token_id = model_no_weights.decoder.config.pad_token_id\n",
    "model_no_weights.config.eos_token_id = model_no_weights.decoder.config.eos_token_id\n",
    "model_no_weights.config.max_length = 128\n",
    "model_no_weights.config.encoder.layerdrop = 0.0\n",
    "model_no_weights.config.use_cache = False\n",
    "model_no_weights.config.processor_class = \"Wav2Vec2Processor\"\n",
    "\n",
    "# # Accessing the model configuration\n",
    "# config_encoder = model_no_weights.config.encoder\n",
    "# config_encoder.add_adapter = True\n",
    "# config_decoder = model_no_weights.config.decoder\n",
    "# # set decoder config to causal lm\n",
    "# config_decoder.is_decoder = True\n",
    "# config_decoder.add_cross_attention = True\n",
    "\n",
    "\n",
    "# input_values = feature_extractor(\n",
    "#     voxpopuli_head[0][\"audio\"][\"array\"], return_tensors=\"pt\", sampling_rate=SAMPLING_RATE\n",
    "# ).input_values\n",
    "\n",
    "# generated_ids = model.generate(input_values, decoder_start_token_id=tokenizer.cls_token_id, )\n",
    "# generated_text = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "# print(generated_text)\n",
    "\n",
    "# # load its corresponding transcription and tokenize to generate labels\n",
    "# labels = tokenizer(voxpopuli_head[0][\"text\"], return_tensors=\"pt\").input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "def display_weight_stats(model):\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            mean = param.data.mean().item()\n",
    "            std = param.data.std().item()\n",
    "            print(f\"Layer: {name} | Mean: {mean:.4f} | Std: {std:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSpeechSeq2Seq\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\"../seq2seq_wav2vec2_bart-base_scratch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_weight_stats(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DEBUGGING TO INSPECT THE AUDIO\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa.display\n",
    "\n",
    "# Load and display the original audio\n",
    "audio_orig, sr_orig = librosa.load(\"../tmp/debug/2277-149896-0000_orig.mp3\")\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(audio_orig, sr=sr_orig)\n",
    "plt.title(\"Original Audio\")\n",
    "plt.show()\n",
    "\n",
    "# Load and display the post-feature extracted audio\n",
    "audio_post, sr_post = librosa.load(\"../tmp/debug/2277-149896-0000.mp3\")\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(audio_post, sr=sr_post)\n",
    "plt.title(\"Post-Feature Extracted Audio\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
