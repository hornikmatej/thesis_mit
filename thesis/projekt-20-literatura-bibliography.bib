@article{Corbetta2002,
  author       = {Corbetta, Maurizio and Shulman, Gordon L.},
  title        = {Control of goal-directed and stimulus-driven attention in the brain},
  journal      = {Nature Reviews Neuroscience},
  year         = {2002},
  volume       = {3},
  number       = {3},
  pages        = {201--215},
  month        = mar,
  doi          = {10.1038/nrn755},
  pmid         = {11994752}
}

@misc{Martinez2025_OCRAccuracy,
  author       = {Jorge Martinez},
  title        = {What is the {OCR} Accuracy and How it Can be Improved},
  year         = {2025},
  month        = {January},
  howpublished = {\url{https://www.docuclipper.com/blog/ocr-accuracy/}},
  note         = {Date: January 6, 2025. Viewed 24.4.2025}
}

@inproceedings{Kahn_2020,
   title={Libri-Light: A Benchmark for ASR with Limited or No Supervision},
   url={http://dx.doi.org/10.1109/ICASSP40776.2020.9052942},
   DOI={10.1109/icassp40776.2020.9052942},
   booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   publisher={IEEE},
   author={Kahn, J. and Riviere, M. and Zheng, W. and Kharitonov, E. and Xu, Q. and Mazare, P.E. and Karadayi, J. and Liptchinsky, V. and Collobert, R. and Fuegen, C. and Likhomanenko, T. and Synnaeve, G. and Joulin, A. and Mohamed, A. and Dupoux, E.},
   year={2020},
   month=may, pages={7669–7673} }


@misc{lewis2019bartdenoisingsequencetosequencepretraining,
      title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, 
      author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
      year={2019},
      eprint={1910.13461},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.13461}, 
}
@misc{ha2016hypernetworks,
    title={HyperNetworks},
    author={David Ha and Andrew Dai and Quoc V. Le},
    year={2016},
    eprint={1609.09106},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@InProceedings{hinton1987using,
  title = {Using Fast Weights to Deblur Old Memories},
  author = {Hinton, Geoffrey E. and Plaut, David C.},
  booktitle = {Proceedings of the   
 Annual Meeting of the Cognitive Science Society},
  volume = {9},
  year = {1987},
  url = {https://escholarship.org/uc/item/0570j1dp},
}

@misc{loshchilov2019decoupledweightdecayregularization,
      title={Decoupled Weight Decay Regularization}, 
      author={Ilya Loshchilov and Frank Hutter},
      year={2019},
      eprint={1711.05101},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1711.05101}, 
}

@misc{hu2021lora,
    title={LoRA: Low-Rank Adaptation of Large Language Models},
    author={Edward J. Hu and Yelong Shen and Phillip Wallis and Zeyuan Allen-Zhu and Yuanzhi Li and Shean Wang and Lu Wang and Weizhu Chen},
    year={2021},
    eprint={2106.09685},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{vonPlaten2020warmstart,
  author = {Patrick von Platen},
  title = {Leveraging Pre-trained Language Model Checkpoints for Encoder-Decoder Models},
  year = {2020},
  month = {November},
  url = {https://huggingface.co/blog/warm-starting-encoder-decoder},
  note = {Accessed: 2025-01-09}
}

@article{fastweight,
    author = {Schmidhuber, Jürgen},
    title = {Learning to Control Fast-Weight Memories: An Alternative to Dynamic Recurrent Networks},
    journal = {Neural Computation},
    volume = {4},
    number = {1},
    pages = {131-139},
    year = {1992},
    month = {01},
    issn = {0899-7667},
    doi = {10.1162/neco.1992.4.1.131},
    url = {https://doi.org/10.1162/neco.1992.4.1.131},
    eprint = {https://direct.mit.edu/neco/article-pdf/4/1/131/812242/neco.1992.4.1.131.pdf}
}

@misc{xu2023efficient,
    title={Efficient Sequence Transduction by Jointly Predicting Tokens and Durations},
    author={Hainan Xu and Fei Jia and Somshubra Majumdar and He Huang and Shinji Watanabe and Boris Ginsburg},
    year={2023},
    eprint={2304.06795},
    archivePrefix={arXiv}
}





@misc{schlag2021linear,
    title={Linear Transformers Are Secretly Fast Weight Programmers},
    author={Imanol Schlag and Kazuki Irie and Jürgen Schmidhuber},
    year={2021},
    eprint={2102.11174},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@ARTICLE{730558,
  author={Itti, L. and Koch, C. and Niebur, E.},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={A model of saliency-based visual attention for rapid scene analysis}, 
  year={1998},
  volume={20},
  number={11},
  pages={1254-1259},
  keywords={Image analysis;Layout;Brain modeling;Computer architecture;Biological system modeling;Visual system;Neural networks;Feature extraction;Object detection;Hardware},
  doi={10.1109/34.730558}}

@misc{bahdanau2014neural,
    title={Neural Machine Translation by Jointly Learning to Align and Translate},
    author={Dzmitry Bahdanau and Kyunghyun Cho and Yoshua Bengio},
    year={2014},
    eprint={1409.0473},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{liu2024dora,
    title={DoRA: Weight-Decomposed Low-Rank Adaptation},
    author={Shih-Yang Liu and Chien-Yi Wang and Hongxu Yin and Pavlo Molchanov and Yu-Chiang Frank Wang and Kwang-Ting Cheng and Min-Hung Chen},
    year={2024},
    eprint={2402.09353},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{kalamkar2019study,
    title={A Study of BFLOAT16 for Deep Learning Training},
    author={Dhiraj Kalamkar and Dheevatsa Mudigere and Naveen Mellempudi and Dipankar Das and Kunal Banerjee and Sasikanth Avancha and Dharma Teja Vooturi and Nataraj Jammalamadaka and Jianyu Huang and Hector Yuen and Jiyan Yang and Jongsoo Park and Alexander Heinecke and Evangelos Georganas and Sudarshan Srinivasan and Abhisek Kundu and Misha Smelyanskiy and Bharat Kaul and Pradeep Dubey},
    year={2019},
    eprint={1905.12322},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{wang2021voxpopulilargescalemultilingualspeech,
      title={VoxPopuli: A Large-Scale Multilingual Speech Corpus for Representation Learning, Semi-Supervised Learning and Interpretation}, 
      author={Changhan Wang and Morgane Rivière and Ann Lee and Anne Wu and Chaitanya Talnikar and Daniel Haziza and Mary Williamson and Juan Pino and Emmanuel Dupoux},
      year={2021},
      eprint={2101.00390},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2101.00390}, 
}
@misc{graves2012sequence,
    title={Sequence Transduction with Recurrent Neural Networks},
    author={Alex Graves},
    year={2012},
    eprint={1211.3711},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@inproceedings{graves2006connectionist,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@inproceedings{graves2014towards,
  title={Towards end-to-end speech recognition with recurrent neural networks},
  author={Graves, Alex and Jaitly, Navdeep},
  booktitle={International conference on machine learning},
  pages={1764--1772},
  year={2014},
  organization={PMLR}
}
@misc{chorowski2015attentionbased,
    title={Attention-Based Models for Speech Recognition},
    author={Jan Chorowski and Dzmitry Bahdanau and Dmitriy Serdyuk and Kyunghyun Cho and Yoshua Bengio},
    year={2015},
    eprint={1506.07503},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{hannun2014deep,
    title={Deep Speech: Scaling up end-to-end speech recognition},
    author={Awni Hannun and Carl Case and Jared Casper and Bryan Catanzaro and Greg Diamos and Erich Elsen and Ryan Prenger and Sanjeev Satheesh and Shubho Sengupta and Adam Coates and Andrew Y. Ng},
    year={2014},
    eprint={1412.5567},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
@inproceedings{Miao_2015,
   title={EESEN: End-to-end speech recognition using deep RNN models and WFST-based decoding},
   url={http://dx.doi.org/10.1109/ASRU.2015.7404790},
   DOI={10.1109/asru.2015.7404790},
   booktitle={2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU)},
   publisher={IEEE},
   author={Miao, Yajie and Gowayyed, Mohammad and Metze, Florian},
   year={2015},
   month=dec, pages={167–174} 
}



@article{Das_2019,
   title={Advancing Acoustic-to-Word CTC Model With Attention and Mixed-Units},
   volume={27},
   ISSN={2329-9304},
   url={http://dx.doi.org/10.1109/TASLP.2019.2933325},
   DOI={10.1109/taslp.2019.2933325},
   number={12},
   journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Das, Amit and Li, Jinyu and Ye, Guoli and Zhao, Rui and Gong, Yifan},
   year={2019},
   month=dec, pages={1880–1892} 
}



@inproceedings{Chan_2016,
   title={Listen, attend and spell: A neural network for large vocabulary conversational speech recognition},
   url={http://dx.doi.org/10.1109/ICASSP.2016.7472621},
   DOI={10.1109/icassp.2016.7472621},
   booktitle={2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   publisher={IEEE},
   author={Chan, William and Jaitly, Navdeep and Le, Quoc and Vinyals, Oriol},
   year={2016},
   month=mar }


@article{KHEDDAR2024102422,
title = {Automatic speech recognition using advanced deep learning approaches: A survey},
journal = {Information Fusion},
volume = {109},
pages = {102422},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102422},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524002008},
author = {Hamza Kheddar and Mustapha Hemis and Yassine Himeur},
keywords = {Automatic speech recognition, Deep transfer learning, Transformers, Federated learning, Reinforcement learning}
}

@article{Li_2022,
   title={Recent Advances in End-to-End Automatic Speech Recognition},
   volume={11},
   ISSN={2048-7703},
   url={http://dx.doi.org/10.1561/116.00000050},
   DOI={10.1561/116.00000050},
   number={1},
   journal={APSIPA Transactions on Signal and Information Processing},
   publisher={Now Publishers},
   author={Li, Jinyu},
   year={2022} }


@INPROCEEDINGS{libri,
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Librispeech: An ASR corpus based on public domain audio books}, 
  year={2015},
  volume={},
  number={},
  pages={5206-5210},
  keywords={Resource description framework;Genomics;Bioinformatics;Blogs;Information services;Electronic publishing;Speech Recognition;Corpus;LibriVox},
  doi={10.1109/ICASSP.2015.7178964}}


@article{mms,
author = {Pratap, Vineel and Tjandra, Andros and Shi, Bowen and Tomasello, Paden and Babu, Arun and Kundu, Sayani and Elkahky, Ali and Ni, Zhaoheng and Vyas, Apoorv and Fazel-Zarandi, Maryam and Baevski, Alexei and Adi, Yossi and Zhang, Xiaohui and Hsu, Wei-Ning and Conneau, Alexis and Auli, Michael},
title = {Scaling speech technology to 1,000+ languages},
year = {2024},
issue_date = {January 2024},
publisher = {JMLR.org},
volume = {25},
number = {1},
issn = {1532-4435},
abstract = {Expanding the language coverage of speech technology has the potential to improve access to information for many more people. However, current speech technology is restricted to about one hundred languages which is a small fraction of the over 7,000 languages spoken around the world. The Massively Multilingual Speech (MMS) project increases the number of supported languages by 10-40x, depending on the task while providing improved accuracy compared to prior work. The main ingredients are a new dataset based on readings of publicly available religious texts and effectively leveraging self-supervised learning. We built pre-trained wav2vec 2.0 models covering 1,406 languages, a single multilingual automatic speech recognition model for 1,107 languages, speech synthesis models for the same number of languages, as well as a language identification model for 4,017 languages. Experiments show that our multilingual speech recognition model more than halves the word error rate of Whisper on 54 languages of the FLEURS benchmark while being trained on a small fraction of the labeled data. The MMS models and tooling for data pre-processing are available at https://github.com/pytorch/fairseq/tree/master/examples/mms.},
journal = {J. Mach. Learn. Res.},
month = jan,
articleno = {97},
numpages = {52},
keywords = {multilingual speech processing, self-supervised learning, language expansion, neural networks}
}

@inproceedings{Babu2022XLS,
  author    = {Arun Babu and Changhan Wang and Andros Tjandra and Kushal Lakhotia and Qiantong Xu and Naman Goyal and Kritika Singh and Patrick {von Platen} and Yatharth Saraf and Juan Pino and Alexei Baevski and Alexis Conneau and Michael Auli},
  title     = {{XLS-R: Self-supervised Cross-lingual Speech Representation Learning at Scale}},
  booktitle = {Proceedings of Interspeech 2022},
  year      = {2022},
  month     = {sep},
  pages     = {2278--2282},
  publisher = {ISCA},
  address   = {Incheon, Korea},
  doi       = {10.21437/interspeech.2022-143},
  url       = {http://dx.doi.org/10.21437/interspeech.2022-143}
}


@inproceedings{watanabe2018espnet,
  author={Shinji Watanabe and Takaaki Hori and Shigeki Karita and Tomoki Hayashi and Jiro Nishitoba and Yuya Unno and Nelson {Enrique Yalta Soplin} and Jahn Heymann and Matthew Wiesner and Nanxin Chen and Adithya Renduchintala and Tsubasa Ochiai},
  title={{ESPnet}: End-to-End Speech Processing Toolkit},
  year={2018},
  booktitle={Proceedings of Interspeech},
  pages={2207--2211},
  doi={10.21437/Interspeech.2018-1456},
  url={http://dx.doi.org/10.21437/Interspeech.2018-1456}
}

@inproceedings{Mu2SLAM,
author = {Cheng, Yong and Zhang, Yu and Johnson, Melvin and Macherey, Wolfgang and Bapna, Ankur},
title = {Mu2SLAM: multitask, multilingual speech and language models},
year = {2023},
publisher = {JMLR.org},
abstract = {We present Mu2SLAM, a multilingual sequence-to-sequence model pre-trained jointly on unlabeled speech, unlabeled text and supervised data spanning Automatic Speech Recognition (ASR), Automatic Speech Translation (AST) and Machine Translation (MT), in over 100 languages. By leveraging a quantized representation of speech as a target, Mu2SLAM trains the speech-text models with a sequence-to-sequence masked denoising objective similar to T5 on the decoder and a masked language modeling objective (MLM) on the encoder, for both unlabeled speech and text, while utilizing the supervised tasks to improve cross-lingual and cross-modal representation alignment within the model. On CoVoST AST, Mu2SLAM establishes a new state-of-the-art for models trained on public datasets, improving on xx-en translation over the previous best by 1.9 BLEU points and on en-xx translation by 1.1 BLEU points. On Voxpopuli ASR, our model matches the performance of an mSLAM model fine-tuned with an RNN-T decoder, despite using a relatively weaker Transformer decoder. On text understanding tasks, our model improves by more than 6\% over mSLAM on XNLI, getting closer to the performance of mT5 models of comparable capacity on XNLI and TydiQA, paving the way towards a single model for all speech and text understanding tasks.},
booktitle = {Proceedings of the 40th International Conference on Machine Learning},
articleno = {219},
numpages = {17},
location = {Honolulu, Hawaii, USA},
series = {ICML'23}
}



@article{FUKUSHIMA1988119,
title = {Neocognitron: A hierarchical neural network capable of visual pattern recognition},
journal = {Neural Networks},
volume = {1},
number = {2},
pages = {119-130},
year = {1988},
issn = {0893-6080},
doi = {https://doi.org/10.1016/0893-6080(88)90014-7},
url = {https://www.sciencedirect.com/science/article/pii/0893608088900147},
author = {Kunihiko Fukushima},
}

@misc{zhang2019rootmeansquarelayer,
      title={Root Mean Square Layer Normalization}, 
      author={Biao Zhang and Rico Sennrich},
      year={2019},
      eprint={1910.07467},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1910.07467}, 
}

@misc{xiong2020layernormalizationtransformerarchitecture,
      title={On Layer Normalization in the Transformer Architecture}, 
      author={Ruibin Xiong and Yunchang Yang and Di He and Kai Zheng and Shuxin Zheng and Chen Xing and Huishuai Zhang and Yanyan Lan and Liwei Wang and Tie-Yan Liu},
      year={2020},
      eprint={2002.04745},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2002.04745}, 
}

@inproceedings{Kudo_2018,
   title={SentencePiece: A simple and language independent subword tokenizer and detokenizer for Neural Text Processing},
   url={http://dx.doi.org/10.18653/v1/D18-2012},
   DOI={10.18653/v1/d18-2012},
   booktitle={Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations},
   publisher={Association for Computational Linguistics},
   author={Kudo, Taku and Richardson, John},
   year={2018} }

@misc{lewis2019bartdenoisingsequencetosequencepretraining,
      title={BART: Denoising Sequence-to-Sequence Pre-training for Natural Language Generation, Translation, and Comprehension}, 
      author={Mike Lewis and Yinhan Liu and Naman Goyal and Marjan Ghazvininejad and Abdelrahman Mohamed and Omer Levy and Ves Stoyanov and Luke Zettlemoyer},
      year={2019},
      eprint={1910.13461},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1910.13461}, 
}


@misc{unigram,
      title={Subword Regularization: Improving Neural Network Translation Models with Multiple Subword Candidates}, 
      author={Taku Kudo},
      year={2018},
      eprint={1804.10959},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1804.10959}, 
}

@misc{huggingface2025transformers,
  title = {Transformers Library - SpeechEncoderDecoder Documentation},
  author = {Hugging Face},
  year = {2025},
  url = {https://huggingface.co/docs/transformers/main/en/model_doc/speech-encoder-decoder},
  note = {Accessed: 2025-01-09}
}

@misc{baevski2020wav2vec20frameworkselfsupervised,
      title={wav2vec 2.0: A Framework for Self-Supervised Learning of Speech Representations}, 
      author={Alexei Baevski and Henry Zhou and Abdelrahman Mohamed and Michael Auli},
      year={2020},
      eprint={2006.11477},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2006.11477}, 
}

@misc{wordpiece,
      title={Google's Neural Machine Translation System: Bridging the Gap between Human and Machine Translation}, 
      author={Yonghui Wu and Mike Schuster and Zhifeng Chen and Quoc V. Le and Mohammad Norouzi and Wolfgang Macherey and Maxim Krikun and Yuan Cao and Qin Gao and Klaus Macherey and Jeff Klingner and Apurva Shah and Melvin Johnson and Xiaobing Liu and Łukasz Kaiser and Stephan Gouws and Yoshikiyo Kato and Taku Kudo and Hideto Kazawa and Keith Stevens and George Kurian and Nishant Patil and Wei Wang and Cliff Young and Jason Smith and Jason Riesa and Alex Rudnick and Oriol Vinyals and Greg Corrado and Macduff Hughes and Jeffrey Dean},
      year={2016},
      eprint={1609.08144},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1609.08144}, 
}

@inproceedings{gulati2020conformer,
  title        = {Conformer: Convolution-augmented Transformer for Speech Recognition},
  author       = {Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and Pang, Ruoming},
  booktitle    = {Proceedings of the Annual Conference of the International Speech Communication Association (Interspeech 2020)},
  year         = {2020},
  month        = oct,
  publisher    = {ISCA},
  pages        = {5036--5040},
  doi          = {10.21437/Interspeech.2020-3015},
  url          = {https://doi.org/10.21437/Interspeech.2020-3015}
}



@article{Hsu_2021,
   title={HuBERT: Self-Supervised Speech Representation Learning by Masked Prediction of Hidden Units},
   volume={29},
   ISSN={2329-9304},
   url={http://dx.doi.org/10.1109/taslp.2021.3122291},
   DOI={10.1109/taslp.2021.3122291},
   journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Hsu, Wei-Ning and Bolte, Benjamin and Tsai, Yao-Hung Hubert and Lakhotia, Kushal and Salakhutdinov, Ruslan and Mohamed, Abdelrahman},
   year={2021},
   pages={3451–3460} }


@inproceedings{Rust_2021,
   title={How Good is Your Tokenizer? On the Monolingual Performance of Multilingual Language Models},
   url={http://dx.doi.org/10.18653/v1/2021.acl-long.243},
   DOI={10.18653/v1/2021.acl-long.243},
   booktitle={Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
   publisher={Association for Computational Linguistics},
   author={Rust, Phillip and Pfeiffer, Jonas and Vulić, Ivan and Ruder, Sebastian and Gurevych, Iryna},
   year={2021} }


@inproceedings{bpe_sennrich-etal-2016-neural,
    title = "Neural Machine Translation of Rare Words with Subword Units",
    author = "Sennrich, Rico  and Haddow, Barry  and Birch, Alexandra",
    editor = "Erk, Katrin  and Smith, Noah A.",
    booktitle = "Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = aug,
    year = "2016",
    address = "Berlin, Germany",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P16-1162",
    doi = "10.18653/v1/P16-1162",
    pages = "1715--1725"
}

@misc{press2022trainshorttestlong,
      title={Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation}, 
      author={Ofir Press and Noah A. Smith and Mike Lewis},
      year={2022},
      eprint={2108.12409},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2108.12409}, 
}

@misc{huggingface_whisper_large_v3_card,
  author       = {OpenAI and Hugging Face},
  title        = {Model card for openai/whisper-large-v3},
  year         = {2023},
  howpublished = {\url{https://huggingface.co/openai/whisper-large-v3}},
  note         = {Accessed: 1.5.2025}
}

@misc{he2021unified,
    title={Towards a Unified View of Parameter-Efficient Transfer Learning},
    author={Junxian He and Chunting Zhou and Xuezhe Ma and Taylor Berg-Kirkpatrick and Graham Neubig},
    year={2021},
    eprint={2110.04366},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{he2022hyperprompt,
    title={HyperPrompt: Prompt-based Task-Conditioning of Transformers},
    author={Yun He and Huaixiu Steven Zheng and Yi Tay and Jai Gupta and Yu Du and Vamsi Aribandi and Zhe Zhao and YaGuang Li and Zhao Chen and Donald Metzler and Heng-Tze Cheng and Ed H. Chi},
    year={2022},
    eprint={2203.00759},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{sung2022lst,
    title={LST: Ladder Side-Tuning for Parameter and Memory Efficient Transfer Learning},
    author={Yi-Lin Sung and Jaemin Cho and Mohit Bansal},
    year={2022},
    eprint={2206.06522},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{yang2022parameterefficient,
    title={Parameter-Efficient Tuning with Special Token Adaptation},
    author={Xiaocong Yang and James Y. Huang and Wenxuan Zhou and Muhao Chen},
    year={2022},
    eprint={2210.04382},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{zaken2021bitfit,
    title={BitFit: Simple Parameter-efficient Fine-tuning for Transformer-based Masked Language-models},
    author={Elad Ben Zaken and Shauli Ravfogel and Yoav Goldberg},
    year={2021},
    eprint={2106.10199},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{fu2022effectiveness,
    title={On the Effectiveness of Parameter-Efficient Fine-Tuning},
    author={Zihao Fu and Haoran Yang and Anthony Man-Cho So and Wai Lam and Lidong Bing and Nigel Collier},
    year={2022},
    eprint={2211.15583},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{NEURIPS2022_4027fc45,
 author = {Hu, Shengding and Zhang, Zhen and Ding, Ning and Wang, Yadao and Wang, Yasheng and Liu, Zhiyuan and Sun, Maosong},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},
 pages = {9853--9865},
 publisher = {Curran Associates, Inc.},
 title = {Sparse Structure Search for Delta Tuning},
 url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/4027fc4573ec9114182d1fef37a6321a-Paper-Conference.pdf},
 volume = {35},
 year = {2022}
}


@article{Zhou_2024,
   title={<scp>AutoPEFT</scp>: Automatic Configuration Search for Parameter-Efficient Fine-Tuning},
   volume={12},
   ISSN={2307-387X},
   url={http://dx.doi.org/10.1162/tacl_a_00662},
   DOI={10.1162/tacl_a_00662},
   journal={Transactions of the Association for Computational Linguistics},
   publisher={MIT Press},
   author={Zhou, Han and Wan, Xingchen and Vulić, Ivan and Korhonen, Anna},
   year={2024},
   pages={525–542} }




@misc{mao2021unipelt,
    title={UniPELT: A Unified Framework for Parameter-Efficient Language Model Tuning},
    author={Yuning Mao and Lambert Mathias and Rui Hou and Amjad Almahairi and Hao Ma and Jiawei Han and Wen-tau Yih and Madian Khabsa},
    year={2021},
    eprint={2110.07577},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{he2021unified,
    title={Towards a Unified View of Parameter-Efficient Transfer Learning},
    author={Junxian He and Chunting Zhou and Xuezhe Ma and Taylor Berg-Kirkpatrick and Graham Neubig},
    year={2021},
    eprint={2110.04366},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{zhang2023lorafa,
    title={LoRA-FA: Memory-efficient Low-rank Adaptation for Large Language Models Fine-tuning},
    author={Longteng Zhang and Lin Zhang and Shaohuai Shi and Xiaowen Chu and Bo Li},
    year={2023},
    eprint={2308.03303},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{yang2023bayesian,
    title={Bayesian Low-rank Adaptation for Large Language Models},
    author={Adam X. Yang and Maxime Robeyns and Xi Wang and Laurence Aitchison},
    year={2023},
    eprint={2308.13111},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{Zhang_2024,
   title={LoRAPrune: Structured Pruning Meets Low-Rank Parameter-Efficient Fine-Tuning},
   url={http://dx.doi.org/10.18653/v1/2024.findings-acl.178},
   DOI={10.18653/v1/2024.findings-acl.178},
   booktitle={Findings of the Association for Computational Linguistics ACL 2024},
   publisher={Association for Computational Linguistics},
   author={Zhang, Mingyang and Chen, Hao and Shen, Chunhua and Yang, Zhen and Ou, Linlin and Yu, Xinyi and Zhuang, Bohan},
   year={2024},
   pages={3013–3026} }


@misc{zhang2023adalora,
    title={AdaLoRA: Adaptive Budget Allocation for Parameter-Efficient Fine-Tuning},
    author={Qingru Zhang and Minshuo Chen and Alexander Bukharin and Nikos Karampatziakis and Pengcheng He and Yu Cheng and Weizhu Chen and Tuo Zhao},
    year={2023},
    eprint={2303.10512},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@misc{xu2023qalora,
    title={QA-LoRA: Quantization-Aware Low-Rank Adaptation of Large Language Models},
    author={Yuhui Xu and Lingxi Xie and Xiaotao Gu and Xin Chen and Heng Chang and Hengheng Zhang and Zhengsu Chen and Xiaopeng Zhang and Qi Tian},
    year={2023},
    eprint={2309.14717},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{li2023loftq,
    title={LoftQ: LoRA-Fine-Tuning-Aware Quantization for Large Language Models},
    author={Yixiao Li and Yifan Yu and Chen Liang and Pengcheng He and Nikos Karampatziakis and Weizhu Chen and Tuo Zhao},
    year={2023},
    eprint={2310.08659},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{dettmers2023qlora,
    title={QLoRA: Efficient Finetuning of Quantized LLMs},
    author={Tim Dettmers and Artidoro Pagnoni and Ari Holtzman and Luke Zettlemoyer},
    year={2023},
    eprint={2305.14314},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{edalati2022krona,
    title={KronA: Parameter Efficient Tuning with Kronecker Adapter},
    author={Ali Edalati and Marzieh Tahaei and Ivan Kobyzev and Vahid Partovi Nia and James J. Clark and Mehdi Rezagholizadeh},
    year={2022},
    eprint={2212.10650},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{guo-etal-2021-parameter,
    title = "Parameter-Efficient Transfer Learning with Diff Pruning",
    author = "Guo, Demi  and
      Rush, Alexander  and
      Kim, Yoon",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.378/",
    doi = "10.18653/v1/2021.acl-long.378",
    pages = "4884--4896",
    abstract = "The large size of pretrained networks makes them difficult to deploy for multiple tasks in storage-constrained settings. Diff pruning enables parameter-efficient transfer learning that scales well with new tasks. The approach learns a task-specific {\textquotedblleft}diff{\textquotedblright} vector that extends the original pretrained parameters. This diff vector is adaptively pruned during training with a differentiable approximation to the L0-norm penalty to encourage sparsity. As the number of tasks increases, diff pruning remains parameter-efficient, as it requires storing only a small diff vector for each task. Since it does not require access to all tasks during training, it is attractive in on-device deployment settings where tasks arrive in stream or even from different providers. Diff pruning can match the performance of finetuned baselines on the GLUE benchmark while only modifying 0.5{\%} of the pretrained model`s parameters per task and scales favorably in comparison to popular pruning approaches."
}

@inproceedings{Ansell_2022,
   title={Composable Sparse Fine-Tuning for Cross-Lingual Transfer},
   url={http://dx.doi.org/10.18653/v1/2022.acl-long.125},
   DOI={10.18653/v1/2022.acl-long.125},
   booktitle={Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
   publisher={Association for Computational Linguistics},
   author={Ansell, Alan and Ponti, Edoardo and Korhonen, Anna and Vulić, Ivan},
   year={2022},
   pages={1778–1796} }


@misc{sung2021training,
    title={Training Neural Networks with Fixed Sparse Masks},
    author={Yi-Lin Sung and Varun Nair and Colin Raffel},
    year={2021},
    eprint={2111.09839},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{Zhao_2020,
   title={Masking as an Efficient Alternative to Finetuning for Pretrained Language Models},
   url={http://dx.doi.org/10.18653/v1/2020.emnlp-main.174},
   DOI={10.18653/v1/2020.emnlp-main.174},
   booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
   publisher={Association for Computational Linguistics},
   author={Zhao, Mengjie and Lin, Tao and Mi, Fei and Jaggi, Martin and Schütze, Hinrich},
   year={2020} }


@misc{liu2022fewshot,
    title={Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning},
    author={Haokun Liu and Derek Tam and Mohammed Muqeeth and Jay Mohta and Tenghao Huang and Mohit Bansal and Colin Raffel},
    year={2022},
    eprint={2205.05638},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{lester-etal-2021-power,
    title = "The Power of Scale for Parameter-Efficient Prompt Tuning",
    author = "Lester, Brian  and
      Al-Rfou, Rami  and
      Constant, Noah",
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.243/",
    doi = "10.18653/v1/2021.emnlp-main.243",
    pages = "3045--3059",
    abstract = "In this work, we explore {\textquotedblleft}prompt tuning,{\textquotedblright} a simple yet effective mechanism for learning {\textquotedblleft}soft prompts{\textquotedblright} to condition frozen language models to perform specific downstream tasks. Unlike the discrete text prompts used by GPT-3, soft prompts are learned through backpropagation and can be tuned to incorporate signals from any number of labeled examples. Our end-to-end learned approach outperforms GPT-3`s few-shot learning by a large margin. More remarkably, through ablations on model size using T5, we show that prompt tuning becomes more competitive with scale: as models exceed billions of parameters, our method {\textquotedblleft}closes the gap{\textquotedblright} and matches the strong performance of model tuning (where all model weights are tuned). This finding is especially relevant because large models are costly to share and serve and the ability to reuse one frozen model for multiple downstream tasks can ease this burden. Our method can be seen as a simplification of the recently proposed {\textquotedblleft}prefix tuning{\textquotedblright} of Li and Liang (2021) and we provide a comparison to this and other similar approaches. Finally, we show that conditioning a frozen model with soft prompts confers benefits in robustness to domain transfer and enables efficient {\textquotedblleft}prompt ensembling.{\textquotedblright} We release code and model checkpoints to reproduce our experiments."
}

@inproceedings{li-liang-2021-prefix,
    title = "Prefix-Tuning: Optimizing Continuous Prompts for Generation",
    author = "Li, Xiang Lisa  and
      Liang, Percy",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-long.353/",
    doi = "10.18653/v1/2021.acl-long.353",
    pages = "4582--4597",
    abstract = "Fine-tuning is the de facto way of leveraging large pretrained language models for downstream tasks. However, fine-tuning modifies all the language model parameters and therefore necessitates storing a full copy for each task. In this paper, we propose prefix-tuning, a lightweight alternative to fine-tuning for natural language generation tasks, which keeps language model parameters frozen and instead optimizes a sequence of continuous task-specific vectors, which we call the prefix. Prefix-tuning draws inspiration from prompting for language models, allowing subsequent tokens to attend to this prefix as if it were {\textquotedblleft}virtual tokens{\textquotedblright}. We apply prefix-tuning to GPT-2 for table-to-text generation and to BART for summarization. We show that by learning only 0.1{\%} of the parameters, prefix-tuning obtains comparable performance in the full data setting, outperforms fine-tuning in low-data settings, and extrapolates better to examples with topics that are unseen during training."
}


@inproceedings{pfeiffer-etal-2021-adapterfusion,
    title = "{A}dapter{F}usion: Non-Destructive Task Composition for Transfer Learning",
    author = {Pfeiffer, Jonas  and
      Kamath, Aishwarya  and
      R{\"u}ckl{\'e}, Andreas  and
      Cho, Kyunghyun  and
      Gurevych, Iryna},
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.39/",
    doi = "10.18653/v1/2021.eacl-main.39",
    pages = "487--503",
    abstract = "Sequential fine-tuning and multi-task learning are methods aiming to incorporate knowledge from multiple tasks; however, they suffer from catastrophic forgetting and difficulties in dataset balancing. To address these shortcomings, we propose AdapterFusion, a new two stage learning algorithm that leverages knowledge from multiple tasks. First, in the knowledge extraction stage we learn task specific parameters called adapters, that encapsulate the task-specific information. We then combine the adapters in a separate knowledge composition step. We show that by separating the two stages, i.e., knowledge extraction and knowledge composition, the classifier can effectively exploit the representations learned from multiple tasks in a non-destructive manner. We empirically evaluate AdapterFusion on 16 diverse NLU tasks, and find that it effectively combines various types of knowledge at different layers of the model. We show that our approach outperforms traditional strategies such as full fine-tuning as well as multi-task learning. Our code and adapters are available at AdapterHub.ml."
}


@inproceedings{ruckle-etal-2021-adapterdrop,
    title = "{AdapterDrop}: {O}n the Efficiency of Adapters in Transformers",
    author = {R{\"u}ckl{\'e}, Andreas  and
      Geigle, Gregor  and
      Glockner, Max  and
      Beck, Tilman  and
      Pfeiffer, Jonas  and
      Reimers, Nils  and
      Gurevych, Iryna},
    editor = "Moens, Marie-Francine  and
      Huang, Xuanjing  and
      Specia, Lucia  and
      Yih, Scott Wen-tau",
    booktitle = "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing",
    month = nov,
    year = "2021",
    address = "Online and Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.emnlp-main.626/",
    doi = "10.18653/v1/2021.emnlp-main.626",
    pages = "7930--7946",
    abstract = "Transformer models are expensive to fine-tune, slow for inference, and have large storage requirements. Recent approaches tackle these shortcomings by training smaller models, dynamically reducing the model size, and by training light-weight adapters. In this paper, we propose AdapterDrop, removing adapters from lower transformer layers during training and inference, which incorporates concepts from all three directions. We show that AdapterDrop can dynamically reduce the computational overhead when performing inference over multiple tasks simultaneously, with minimal decrease in task performances. We further prune adapters from AdapterFusion, which improves the inference efficiency while maintaining the task performances entirely."
}


@inproceedings{Lin_2020,
   title={Exploring Versatile Generative Language Model Via Parameter-Efficient Transfer Learning},
   url={http://dx.doi.org/10.18653/v1/2020.findings-emnlp.41},
   DOI={10.18653/v1/2020.findings-emnlp.41},
   booktitle={Findings of the Association for Computational Linguistics: EMNLP 2020},
   publisher={Association for Computational Linguistics},
   author={Lin, Zhaojiang and Madotto, Andrea and Fung, Pascale},
   year={2020} }


@misc{houlsby2019parameterefficient,
    title={Parameter-Efficient Transfer Learning for NLP},
    author={Neil Houlsby and Andrei Giurgiu and Stanislaw Jastrzebski and Bruna Morrone and Quentin de Laroussilhe and Andrea Gesmundo and Mona Attariyan and Sylvain Gelly},
    year={2019},
    eprint={1902.00751},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@misc{xu2023parameterefficient,
    title={Parameter-Efficient Fine-Tuning Methods for Pretrained Language Models: A Critical Review and Assessment},
    author={Lingling Xu and Haoran Xie and Si-Zhao Joe Qin and Xiaohui Tao and Fu Lee Wang},
    year={2023},
    eprint={2312.12148},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{lialin2023scaling,
    title={Scaling Down to Scale Up: A Guide to Parameter-Efficient Fine-Tuning},
    author={Vladislav Lialin and Vijeta Deshpande and Xiaowei Yao and Anna Rumshisky},
    year={2023},
    eprint={2303.15647},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{ding2023parameter,
  title={Parameter-efficient fine-tuning of large-scale pre-trained language models},
  author={Ding, Ning and Qin, Yujia and Yang, Guang and Wei, Fuchao and Yang, Zonghan and Su, Yusheng and Hu, Shengding and Chen, Yulin and Chan, Chi-Min and Chen, Weize and others},
  journal={Nature Machine Intelligence},
  volume={5},
  number={3},
  pages={220--235},
  year={2023},
  publisher={Nature Publishing Group UK London}
}

@misc{puvvada2024accurate,
    title={Less is More: Accurate Speech Recognition \& Translation without Web-Scale Data},
    author={Krishna C. Puvvada and Piotr Żelasko and He Huang and Oleksii Hrinchuk and Nithin Rao Koluguri and Kunal Dhawan and Somshubra Majumdar and Elena Rastorgueva and Zhehuai Chen and Vitaly Lavrukhin and Jagadeesh Balam and Boris Ginsburg},
    year={2024},
    eprint={2406.19674},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{zusag2024crisperwhisper,
  author    = {Mario Zusag and Laurin Wagner and Bernhard Thallinger},
  title     = {{CrisperWhisper}: Accurate Timestamps on Verbatim Speech Transcriptions},
  booktitle = {Proceedings of Interspeech 2024},
  year      = {2024},
  month     = sep,
  pages     = {1265--1269},
  publisher = {ISCA},
  doi       = {10.21437/interspeech.2024-731},
  url       = {https://doi.org/10.21437/interspeech.2024-731}
}




@inproceedings{Press_2017,
   title={Using the Output Embedding to Improve Language Models},
   url={http://dx.doi.org/10.18653/V1/E17-2025},
   DOI={10.18653/v1/e17-2025},
   booktitle={Proceedings of the 15th Conference of the European Chapter of the
          Association for Computational Linguistics: Volume 2, Short Papers},
   publisher={Association for Computational Linguistics},
   author={Press, Ofir and Wolf, Lior},
   year={2017},
   pages={157–163} }


@misc{devlin2019bertpretrainingdeepbidirectional,
      title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}, 
      author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
      year={2019},
      eprint={1810.04805},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1810.04805}, 
}

@misc{su2023roformerenhancedtransformerrotary,
      title={RoFormer: Enhanced Transformer with Rotary Position Embedding}, 
      author={Jianlin Su and Yu Lu and Shengfeng Pan and Ahmed Murtadha and Bo Wen and Yunfeng Liu},
      year={2023},
      eprint={2104.09864},
      archivePrefix={arXiv},
      url={https://arxiv.org/abs/2104.09864}, 
}


@inproceedings{pennington-etal-2014-glove,
    title = "{G}lo{V}e: Global Vectors for Word Representation",
    author = "Pennington, Jeffrey  and
      Socher, Richard  and
      Manning, Christopher",
    editor = "Moschitti, Alessandro  and
      Pang, Bo  and
      Daelemans, Walter",
    booktitle = "Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing ({EMNLP})",
    month = oct,
    year = "2014",
    address = "Doha, Qatar",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/D14-1162",
    doi = "10.3115/v1/D14-1162",
    pages = "1532--1543",
}

@misc{word2vec,
      title={Efficient Estimation of Word Representations in Vector Space}, 
      author={Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
      year={2013},
      eprint={1301.3781},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1301.3781}, 
}

@article{fasttext,
   title={Enriching Word Vectors with Subword Information},
   volume={5},
   ISSN={2307-387X},
   url={http://dx.doi.org/10.1162/tacl_a_00051},
   DOI={10.1162/tacl_a_00051},
   journal={Transactions of the Association for Computational Linguistics},
   publisher={MIT Press},
   author={Bojanowski, Piotr and Grave, Edouard and Joulin, Armand and Mikolov, Tomas},
   year={2017},
   month=dec, pages={135–146} }


@misc{bai2023qwen,
    title={Qwen Technical Report},
    author={Jinze Bai and Shuai Bai and Yunfei Chu and Zeyu Cui and Kai Dang and Xiaodong Deng and Yang Fan and Wenbin Ge and Yu Han and Fei Huang and Binyuan Hui and Luo Ji and Mei Li and Junyang Lin and Runji Lin and Dayiheng Liu and Gao Liu and Chengqiang Lu and Keming Lu and Jianxin Ma and Rui Men and Xingzhang Ren and Xuancheng Ren and Chuanqi Tan and Sinan Tan and Jianhong Tu and Peng Wang and Shijie Wang and Wei Wang and Shengguang Wu and Benfeng Xu and Jin Xu and An Yang and Hao Yang and Jian Yang and Shusheng Yang and Yang Yao and Bowen Yu and Hongyi Yuan and Zheng Yuan and Jianwei Zhang and Xingxuan Zhang and Yichang Zhang and Zhenru Zhang and Chang Zhou and Jingren Zhou and Xiaohuan Zhou and Tianhang Zhu},
    year={2023},
    eprint={2309.16609},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{touvron2023llama,
    title={LLaMA: Open and Efficient Foundation Language Models},
    author={Hugo Touvron and Thibaut Lavril and Gautier Izacard and Xavier Martinet and Marie-Anne Lachaux and Timothée Lacroix and Baptiste Rozière and Naman Goyal and Eric Hambro and Faisal Azhar and Aurelien Rodriguez and Armand Joulin and Edouard Grave and Guillaume Lample},
    year={2023},
    eprint={2302.13971},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@inproceedings{42543,title	= {Word Embeddings for Speech Recognition},author	= {Samy Bengio and Georg Heigold},year	= {2014},booktitle	= {Proceedings of the 15th Conference of the International Speech Communication Association, {Interspeech}}}

@article{kitaev2020reformer,
  title={Reformer: The efficient transformer},
  author={Kitaev, Nikita and Kaiser, {\L}ukasz and Levskaya, Anselm},
  journal={arXiv preprint arXiv:2001.04451},
  year={2020}
}



@ARTICLE{mqa,
  author={Xu, Yangyang and Li, Xiangtai and Yuan, Haobo and Yang, Yibo and Zhang, Lefei},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Multi-Task Learning With Multi-Query Transformer for Dense Prediction}, 
  year={2024},
  volume={34},
  number={2},
  pages={1228-1240},
  keywords={Task analysis;Transformers;Multitasking;Feature extraction;Computational modeling;Decoding;Pipelines;Scene understanding;multi-task learning;dense prediction;transformers},
  doi={10.1109/TCSVT.2023.3292995}}


@article{zaheer2020big,
  title={Big bird: Transformers for longer sequences},
  author={Zaheer, Manzil and Guruganesh, Guru and Dubey, Kumar Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17283--17297},
  year={2020}
}

@misc{open-asr-leaderboard,
	title        = {Open Automatic Speech Recognition Leaderboard},
	author       = {Srivastav, Vaibhav and Majumdar, Somshubra and Koluguri, Nithin and Moumen, Adel and Gandhi, Sanchit and others},
	year         = 2023,
	publisher    = {Hugging Face},
	howpublished = "\url{https://huggingface.co/spaces/hf-audio/open_asr_leaderboard}"
}

@misc{latif2023transformersspeechprocessingsurvey,
      title={Transformers in Speech Processing: A Survey}, 
      author={Siddique Latif and Aun Zaidi and Heriberto Cuayahuitl and Fahad Shamshad and Moazzam Shoukat and Junaid Qadir},
      year={2023},
      eprint={2303.11607},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2303.11607}, 
}

@misc{jiang2023mistral,
    title={Mistral 7B},
    author={Albert Q. Jiang and Alexandre Sablayrolles and Arthur Mensch and Chris Bamford and Devendra Singh Chaplot and Diego de las Casas and Florian Bressand and Gianna Lengyel and Guillaume Lample and Lucile Saulnier and Lélio Renard Lavaud and Marie-Anne Lachaux and Pierre Stock and Teven Le Scao and Thibaut Lavril and Thomas Wang and Timothée Lacroix and William El Sayed},
    year={2023},
    eprint={2310.06825},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{lou2024sparser,
    title={Sparser is Faster and Less is More: Efficient Sparse Attention for Long-Range Transformers},
    author={Chao Lou and Zixia Jia and Zilong Zheng and Kewei Tu},
    year={2024},
    eprint={2406.16747},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@book{Goodfellow-et-al-2016,
    title={Deep Learning},
    author={Ian Goodfellow and Yoshua Bengio and Aaron Courville},
    publisher={MIT Press},
    note={\url{http://www.deeplearningbook.org}},
    year={2016}
}

@misc{cho2014learningphraserepresentationsusing,
      title={Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}, 
      author={Kyunghyun Cho and Bart van Merrienboer and Caglar Gulcehre and Dzmitry Bahdanau and Fethi Bougares and Holger Schwenk and Yoshua Bengio},
      year={2014},
      eprint={1406.1078},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1406.1078}, 
}

@article{Krizhevsky,
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey},
year = {2012},
month = {01},
pages = {},
title = {ImageNet Classification with Deep Convolutional Neural Networks},
volume = {25},
journal = {Neural Information Processing Systems},
doi = {10.1145/3065386}
}

@incollection{robinson1996use,
  title={The use of recurrent neural networks in continuous speech recognition},
  author={Robinson, Tony and Hochberg, Mike and Renals, Steve},
  booktitle={Automatic Speech and Speaker Recognition: Advanced Topics},
  pages={233--258},
  year={1996},
  publisher={Springer}
}


@article{giles1994dynamic,
  title={Dynamic recurrent neural networks: Theory and applications},
  author={Giles, C Lee and Kuhn, Gary M and Williams, Ronald J},
  journal={IEEE Transactions on Neural Networks},
  volume={5},
  number={2},
  pages={153--156},
  year={1994},
  publisher={IEEE}
}


@article{sak2014long,
  title={Long short-term memory recurrent neural network architectures for large scale acoustic modeling},
  author={Sak, Hasim and Senior, Andrew W and Beaufays, Fran{\c{c}}oise},
  year={2014}
}


@article{hochreiter1997long,
  title={Long Short-term Memory},
  author={Hochreiter, S},
  journal={Neural Computation MIT-Press},
  year={1997}
}



@misc{huang2015bidirectional,
    title={Bidirectional LSTM-CRF Models for Sequence Tagging},
    author={Zhiheng Huang and Wei Xu and Kai Yu},
    year={2015},
    eprint={1508.01991},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{chung2014empirical,
    title={Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling},
    author={Junyoung Chung and Caglar Gulcehre and KyungHyun Cho and Yoshua Bengio},
    year={2014},
    eprint={1412.3555},
    archivePrefix={arXiv},
    primaryClass={cs.NE}
}

@misc{chung2014empiricalevaluationgatedrecurrent,
      title={Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling}, 
      author={Junyoung Chung and Caglar Gulcehre and KyungHyun Cho and Yoshua Bengio},
      year={2014},
      eprint={1412.3555},
      archivePrefix={arXiv},
      primaryClass={cs.NE},
      url={https://arxiv.org/abs/1412.3555}, 
}

@misc{sutskever2014sequencesequencelearningneural,
      title={Sequence to Sequence Learning with Neural Networks}, 
      author={Ilya Sutskever and Oriol Vinyals and Quoc V. Le},
      year={2014},
      eprint={1409.3215},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/1409.3215}, 
}

@inbook{inbook_gmm,
author = {Bishop, Christopher},
year = {2006},
month = {01},
pages = {140-155},
title = {Pattern Recognition and Machine Learning},
volume = {16},
journal = {Journal of Electronic Imaging},
doi = {10.1117/1.2819119}
}

@article{o1988linear,
  title={Linear predictive coding},
  author={O'Shaughnessy, Douglas},
  journal={IEEE potentials},
  volume={7},
  number={1},
  pages={29--32},
  year={1988},
  publisher={IEEE}
}


@inproceedings{Yang_2015,
   title={Statistical and computational guarantees for the Baum-Welch algorithm},
   url={http://dx.doi.org/10.1109/ALLERTON.2015.7447067},
   DOI={10.1109/allerton.2015.7447067},
   booktitle={2015 53rd Annual Allerton Conference on Communication, Control, and Computing (Allerton)},
   publisher={IEEE},
   author={Yang, Fanny and Balakrishnan, Sivaraman and Wainwright, Martin J.},
   year={2015},
   month=sep, pages={658–665} }



@BOOK{8187420,
  author={Gales, Mark and Young, Steve},
  booktitle={Application of Hidden Markov Models in Speech Recognition},
  year={2008},
  volume={},
  number={},
  pages={},
  keywords={Electrical and Electronic Engineering;Machine Learning},
  doi={10.1561/2000000004}}



@article{Basak2022,
author = {Basak, Sneha and Agrawal, Himanshi and Jena, Shreya and Gite, Shilpa and Bachute, Mrinal and Pradhan, Biswajeet and Assiri, Mazen},
year = {2022},
month = {10},
pages = {1-37},
title = {Challenges and Limitations in Speech Recognition Technology: A Critical Review of Speech Signal Processing Algorithms, Tools and Systems},
volume = {135},
journal = {Computer Modeling in Engineering \& Sciences},
doi = {10.32604/cmes.2022.021755}
}

@article{Prabhavalkar_2024,
   title={End-to-End Speech Recognition: A Survey},
   volume={32},
   ISSN={2329-9304},
   url={http://dx.doi.org/10.1109/TASLP.2023.3328283},
   DOI={10.1109/taslp.2023.3328283},
   journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
   publisher={Institute of Electrical and Electronics Engineers (IEEE)},
   author={Prabhavalkar, Rohit and Hori, Takaaki and Sainath, Tara N. and Schlüter, Ralf and Watanabe, Shinji},
   year={2024},
   pages={325–351} }


@article{Mehrish_2023,
   title={A review of deep learning techniques for speech processing},
   volume={99},
   ISSN={1566-2535},
   url={http://dx.doi.org/10.1016/j.inffus.2023.101869},
   DOI={10.1016/j.inffus.2023.101869},
   journal={Information Fusion},
   publisher={Elsevier BV},
   author={Mehrish, Ambuj and Majumder, Navonil and Bharadwaj, Rishabh and Mihalcea, Rada and Poria, Soujanya},
   year={2023},
   month=nov, pages={101869} }


@INPROCEEDINGS{7292420,
  author={Chavan, Karishma and Gawande, Ujwalla},
  booktitle={2015 International Conference on Soft-Computing and Networks Security (ICSNS)}, 
  title={Speech recognition in noisy environment, issues and challenges: A review}, 
  year={2015},
  volume={},
  number={},
  pages={1-5},
  keywords={Speech recognition;Speech;Hidden Markov models;Feature extraction;Noise;Mel frequency cepstral coefficient;Noise measurement;Noisy and Clean database;feature extraction;feature recognition},
  doi={10.1109/ICSNS.2015.7292420}}


@article{ghai2012literature,
  title={Literature review on automatic speech recognition},
  author={Ghai, Wiqas and Singh, Navdeep},
  journal={International Journal of Computer Applications},
  volume={41},
  number={8},
  year={2012},
  publisher={Citeseer}
}


@book{yu2014automatic,
  title={Automatic Speech Recognition: A Deep Learning Approach},
  author={Yu, D. and Deng, L.},
  isbn={9781447157793},
  series={Signals and Communication Technology},
  url={https://books.google.cz/books?id=rUBTBQAAQBAJ},
  year={2014},
  publisher={Springer London}
}


@ARTICLE{6296526,
  author={Hinton, Geoffrey and Deng, Li and Yu, Dong and Dahl, George E. and Mohamed, Abdel-rahman and Jaitly, Navdeep and Senior, Andrew and Vanhoucke, Vincent and Nguyen, Patrick and Sainath, Tara N. and Kingsbury, Brian},
  journal={IEEE Signal Processing Magazine}, 
  title={Deep Neural Networks for Acoustic Modeling in Speech Recognition: The Shared Views of Four Research Groups}, 
  year={2012},
  volume={29},
  number={6},
  pages={82-97},
  keywords={Automatic speech recognition;Speech recognition;Hidden Markov models;Training;Gaussian processes;Acoustics;Neural networks;Data models},
  doi={10.1109/MSP.2012.2205597}}



@InProceedings{pmlr-v37-xuc15,
  title = 	 {Show, Attend and Tell: Neural Image Caption Generation with Visual Attention},
  author = 	 {Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle = 	 {Proceedings of the 32nd International Conference on Machine Learning},
  pages = 	 {2048--2057},
  year = 	 {2015},
  editor = 	 {Bach, Francis and Blei, David},
  volume = 	 {37},
  series = 	 {Proceedings of Machine Learning Research},
  address = 	 {Lille, France},
  month = 	 {07--09 Jul},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v37/xuc15.pdf},
  url = 	 {https://proceedings.mlr.press/v37/xuc15.html},
  abstract = 	 {Inspired by recent work in machine translation and object detection, we introduce an attention based model that automatically learns to describe the content of images. We describe how we can train this model in a deterministic manner using standard backpropagation techniques and stochastically by maximizing a variational lower bound. We also show through visualization how the model is able to automatically learn to fix its gaze on salient objects while generating the corresponding words in the output sequence. We validate the use of attention with state-of-the-art performance on three benchmark datasets: Flickr8k, Flickr30k and MS COCO.}
}




@website{Herout,
      author =       "Adam Herout",
      title =        {herout.net -- Poznámky učitele, kouče, čtenáře.},
      howpublished = "online",
      year =         "2018",
      url =          "http://www.herout.net/",
      cited =        "2019-10-02"
    }
   
   
   
    @webpage{Beran,
      author =       "Vítězslav Beran",
      title =        "Beran-BP DP Projekty",
      howpublished = "online",
      year =         "2017",
      url =          "http://merlin.fit.vutbr.cz/wiki/index.php/Beran-BP_DP_Projekty",
      cited =        "2019-10-02"
    }

    @MISC{BeranPDF,
      author =       "Vítězslav Beran",
      title =        "Jak psát technickou zprávu",
      howpublished = "online",
      year =         "2013",
      url =          "http://www.fit.vutbr.cz/~beranv/podpora/Jak\%20psat\%20technickou\%20zpravu.pdf",
      cited =        "2019-10-00"
    }

@misc{vaswani2017attention,
    title={Attention Is All You Need},
    author={Ashish Vaswani and Noam Shazeer and Niki Parmar and Jakob Uszkoreit and Llion Jones and Aidan N. Gomez and Lukasz Kaiser and Illia Polosukhin},
    year={2017},
    eprint={1706.03762},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}
   
    @webpage{rnn,
    key = "Abhisek",
    author = "Abhisel Jana",
    title = "Machine Translation using Recurrent Neural Network and PyTorch",
    howpublished = "online",
    year = "2020-10-24",
    url = "https://adeveloperdiary.com/data-science/deep-learning/nlp/machine-translation-recurrent-neural-network-pytorch/#conclusion",
    cited =        "2024-11-06"
    }

    @webpage{CernockyEnglish,
      key =          "Cernocky",
      author =       "Jan Černocký",
      title =        "English SOS",
      howpublished = "online",
      year =         "2016",
      url =          "https://merlin.fit.vutbr.cz/wiki/index.php/English_SOS",
      cited =        "2019-10-02"
    }

   
    @BOOK{Lebrun2011,
      author =       "Jean-Luc Lebrun",
      title =        "Scientific Writing 2.0: a reader and writer's guide",
      publisher =    "World Scientific Publishing",
      year =         "2011",
      edition =      "1",
      isbn =         "9814350605",
      owner =        "herout",
      timestamp =    "2015.01.20"
    }
  
    @MASTERSTHESIS{Pysny,
      author = {Radek Py{\v{s}}n{\'{y}}},
      type = {Bakal{\'{a}}{\v{r}}sk{\'{a}} pr{\'{a}}ce},
      title = {BiBTeX styl pro {\v{C}}SN ISO 690 a {\v{C}}SN ISO	690-2},
      school = {Vysok{\'{e}} u{\v{c}}en{\'{i}} technick{\'{e}} v Brn{\v{e}}, Fakulta informa{\v{c}}n{\'{i}}ch technologi{\'{i}}},
      year = {2009},
      location = {Brno, CZ},
      language = {czech},
      url = {https://www.fit.vut.cz/study/thesis/7848/}
    }



@inproceedings{soltau2017neural,
  author       = {Hagen Soltau and Hank Liao and Has{\i}m Sak},
  title        = {{Neural Speech Recognizer: Acoustic-to-Word {LSTM} Model for Large Vocabulary Speech Recognition}},
  booktitle    = {Proceedings of the 18th Annual Conference of the International Speech Communication Association (INTERSPEECH 2017)},
  pages        = {3707--3711},
  address      = {Stockholm, Sweden},
  month        = aug,
  year         = {2017},
  publisher    = {ISCA},
  doi          = {10.21437/Interspeech.2017-1566},
  url          = {https://www.isca-archive.org/interspeech_2017/soltau17_interspeech.pdf}
}

@inproceedings{Rekesh_2023,
   title={Fast Conformer With Linearly Scalable Attention For Efficient Speech Recognition},
   url={http://dx.doi.org/10.1109/ASRU57964.2023.10389701},
   DOI={10.1109/asru57964.2023.10389701},
   booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
   publisher={IEEE},
   author={Rekesh, Dima and Koluguri, Nithin Rao and Kriman, Samuel and Majumdar, Somshubra and Noroozi, Vahid and Huang, He and Hrinchuk, Oleksii and Puvvada, Krishna and Kumar, Ankur and Balam, Jagadeesh and Ginsburg, Boris},
   year={2023},
   month=dec, pages={1–8} }


@inproceedings{shi_2021,
   title={Emformer: Efficient Memory Transformer Based Acoustic Model for Low Latency Streaming Speech Recognition},
   url={http://dx.doi.org/10.1109/ICASSP39728.2021.9414560},
   DOI={10.1109/icassp39728.2021.9414560},
   booktitle={ICASSP 2021 - 2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   publisher={IEEE},
   author={Shi, Yangyang and Wang, Yongqiang and Wu, Chunyang and Yeh, Ching-Feng and Chan, Julian and Zhang, Frank and Le, Duc and Seltzer, Mike},
   year={2021},
   month=jun, pages={6783–6787} }


@inproceedings{Dong_2019,
   title={Self-attention Aligner: A Latency-control End-to-end Model for ASR Using Self-attention Network and Chunk-hopping},
   url={http://dx.doi.org/10.1109/ICASSP.2019.8682954},
   DOI={10.1109/icassp.2019.8682954},
   booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   publisher={IEEE},
   author={Dong, Linhao and Wang, Feng and Xu, Bo},
   year={2019},
   month=may, pages={5656–5660} }

@INPROCEEDINGS{8462506,
  author={Dong, Linhao and Xu, Shuang and Xu, Bo},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Speech-Transformer: A No-Recurrence Sequence-to-Sequence Model for Speech Recognition}, 
  year={2018},
  volume={},
  number={},
  pages={5884-5888},
  keywords={Hidden Markov models;Encoding;Training;Decoding;Speech recognition;Time-frequency analysis;Spectrogram;Speech Recognition;Sequence-to-Sequence;Attention;Transformer},
  doi={10.1109/ICASSP.2018.8462506}}

@misc{devlin2018bert,
    title={BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author={Jacob Devlin and Ming-Wei Chang and Kenton Lee and Kristina Toutanova},
    year={2018},
    eprint={1810.04805},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{liu2019roberta,
    title={RoBERTa: A Robustly Optimized BERT Pretraining Approach},
    author={Yinhan Liu and Myle Ott and Naman Goyal and Jingfei Du and Mandar Joshi and Danqi Chen and Omer Levy and Mike Lewis and Luke Zettlemoyer and Veselin Stoyanov},
    year={2019},
    eprint={1907.11692},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={San Francisco, CA, USA}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others}
}

@misc{openai2023gpt4,
    title={GPT-4 Technical Report},
    author={OpenAI and Josh Achiam and Steven Adler and Sandhini Agarwal and Lama Ahmad and Ilge Akkaya and Florencia Leoni Aleman and Diogo Almeida and Janko Altenschmidt and Sam Altman and Shyamal Anadkat and Red Avila and Igor Babuschkin and Suchir Balaji and Valerie Balcom and Paul Baltescu and Haiming Bao and Mohammad Bavarian and Jeff Belgum and Irwan Bello and Jake Berdine and Gabriel Bernadett-Shapiro and Christopher Berner and Lenny Bogdonoff and Oleg Boiko and Madelaine Boyd and Anna-Luisa Brakman and Greg Brockman and Tim Brooks and Miles Brundage and Kevin Button and Trevor Cai and Rosie Campbell and Andrew Cann and Brittany Carey and Chelsea Carlson and Rory Carmichael and Brooke Chan and Che Chang and Fotis Chantzis and Derek Chen and Sully Chen and Ruby Chen and Jason Chen and Mark Chen and Ben Chess and Chester Cho and Casey Chu and Hyung Won Chung and Dave Cummings and Jeremiah Currier and Yunxing Dai and Cory Decareaux and Thomas Degry and Noah Deutsch and Damien Deville and Arka Dhar and David Dohan and Steve Dowling and Sheila Dunning and Adrien Ecoffet and Atty Eleti and Tyna Eloundou and David Farhi and Liam Fedus and Niko Felix and Simón Posada Fishman and Juston Forte and Isabella Fulford and Leo Gao and Elie Georges and Christian Gibson and Vik Goel and Tarun Gogineni and Gabriel Goh and Rapha Gontijo-Lopes and Jonathan Gordon and Morgan Grafstein and Scott Gray and Ryan Greene and Joshua Gross and Shixiang Shane Gu and Yufei Guo and Chris Hallacy and Jesse Han and Jeff Harris and Yuchen He and Mike Heaton and Johannes Heidecke and Chris Hesse and Alan Hickey and Wade Hickey and Peter Hoeschele and Brandon Houghton and Kenny Hsu and Shengli Hu and Xin Hu and Joost Huizinga and Shantanu Jain and Shawn Jain and Joanne Jang and Angela Jiang and Roger Jiang and Haozhun Jin and Denny Jin and Shino Jomoto and Billie Jonn and Heewoo Jun and Tomer Kaftan and Łukasz Kaiser and Ali Kamali and Ingmar Kanitscheider and Nitish Shirish Keskar and Tabarak Khan and Logan Kilpatrick and Jong Wook Kim and Christina Kim and Yongjik Kim and Jan Hendrik Kirchner and Jamie Kiros and Matt Knight and Daniel Kokotajlo and Łukasz Kondraciuk and Andrew Kondrich and Aris Konstantinidis and Kyle Kosic and Gretchen Krueger and Vishal Kuo and Michael Lampe and Ikai Lan and Teddy Lee and Jan Leike and Jade Leung and Daniel Levy and Chak Ming Li and Rachel Lim and Molly Lin and Stephanie Lin and Mateusz Litwin and Theresa Lopez and Ryan Lowe and Patricia Lue and Anna Makanju and Kim Malfacini and Sam Manning and Todor Markov and Yaniv Markovski and Bianca Martin and Katie Mayer and Andrew Mayne and Bob McGrew and Scott Mayer McKinney and Christine McLeavey and Paul McMillan and Jake McNeil and David Medina and Aalok Mehta and Jacob Menick and Luke Metz and Andrey Mishchenko and Pamela Mishkin and Vinnie Monaco and Evan Morikawa and Daniel Mossing and Tong Mu and Mira Murati and Oleg Murk and David Mély and Ashvin Nair and Reiichiro Nakano and Rajeev Nayak and Arvind Neelakantan and Richard Ngo and Hyeonwoo Noh and Long Ouyang and Cullen O'Keefe and Jakub Pachocki and Alex Paino and Joe Palermo and Ashley Pantuliano and Giambattista Parascandolo and Joel Parish and Emy Parparita and Alex Passos and Mikhail Pavlov and Andrew Peng and Adam Perelman and Filipe de Avila Belbute Peres and Michael Petrov and Henrique Ponde de Oliveira Pinto and Michael and Pokorny and Michelle Pokrass and Vitchyr H. Pong and Tolly Powell and Alethea Power and Boris Power and Elizabeth Proehl and Raul Puri and Alec Radford and Jack Rae and Aditya Ramesh and Cameron Raymond and Francis Real and Kendra Rimbach and Carl Ross and Bob Rotsted and Henri Roussez and Nick Ryder and Mario Saltarelli and Ted Sanders and Shibani Santurkar and Girish Sastry and Heather Schmidt and David Schnurr and John Schulman and Daniel Selsam and Kyla Sheppard and Toki Sherbakov and Jessica Shieh and Sarah Shoker and Pranav Shyam and Szymon Sidor and Eric Sigler and Maddie Simens and Jordan Sitkin and Katarina Slama and Ian Sohl and Benjamin Sokolowsky and Yang Song and Natalie Staudacher and Felipe Petroski Such and Natalie Summers and Ilya Sutskever and Jie Tang and Nikolas Tezak and Madeleine B. Thompson and Phil Tillet and Amin Tootoonchian and Elizabeth Tseng and Preston Tuggle and Nick Turley and Jerry Tworek and Juan Felipe Cerón Uribe and Andrea Vallone and Arun Vijayvergiya and Chelsea Voss and Carroll Wainwright and Justin Jay Wang and Alvin Wang and Ben Wang and Jonathan Ward and Jason Wei and CJ Weinmann and Akila Welihinda and Peter Welinder and Jiayi Weng and Lilian Weng and Matt Wiethoff and Dave Willner and Clemens Winter and Samuel Wolrich and Hannah Wong and Lauren Workman and Sherwin Wu and Jeff Wu and Michael Wu and Kai Xiao and Tao Xu and Sarah Yoo and Kevin Yu and Qiming Yuan and Wojciech Zaremba and Rowan Zellers and Chong Zhang and Marvin Zhang and Shengjia Zhao and Tianhao Zheng and Juntang Zhuang and William Zhuk and Barret Zoph},
    year={2023},
    eprint={2303.08774},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{openai2024gpt4o,
    title={GPT-4o System Card},
    author={OpenAI and : and Aaron Hurst and Adam Lerer and Adam P. Goucher and Adam Perelman and Aditya Ramesh and Aidan Clark and AJ Ostrow and Akila Welihinda and Alan Hayes and Alec Radford and Aleksander Mądry and Alex Baker-Whitcomb and Alex Beutel and Alex Borzunov and Alex Carney and Alex Chow and Alex Kirillov and Alex Nichol and Alex Paino and Alex Renzin and Alex Tachard Passos and Alexander Kirillov and Alexi Christakis and Alexis Conneau and Ali Kamali and Allan Jabri and Allison Moyer and Allison Tam and Amadou Crookes and Amin Tootoochian and Amin Tootoonchian and Ananya Kumar and Andrea Vallone and Andrej Karpathy and Andrew Braunstein and Andrew Cann and Andrew Codispoti and Andrew Galu and Andrew Kondrich and Andrew Tulloch and Andrey Mishchenko and Angela Baek and Angela Jiang and Antoine Pelisse and Antonia Woodford and Anuj Gosalia and Arka Dhar and Ashley Pantuliano and Avi Nayak and Avital Oliver and Barret Zoph and Behrooz Ghorbani and Ben Leimberger and Ben Rossen and Ben Sokolowsky and Ben Wang and Benjamin Zweig and Beth Hoover and Blake Samic and Bob McGrew and Bobby Spero and Bogo Giertler and Bowen Cheng and Brad Lightcap and Brandon Walkin and Brendan Quinn and Brian Guarraci and Brian Hsu and Bright Kellogg and Brydon Eastman and Camillo Lugaresi and Carroll Wainwright and Cary Bassin and Cary Hudson and Casey Chu and Chad Nelson and Chak Li and Chan Jun Shern and Channing Conger and Charlotte Barette and Chelsea Voss and Chen Ding and Cheng Lu and Chong Zhang and Chris Beaumont and Chris Hallacy and Chris Koch and Christian Gibson and Christina Kim and Christine Choi and Christine McLeavey and Christopher Hesse and Claudia Fischer and Clemens Winter and Coley Czarnecki and Colin Jarvis and Colin Wei and Constantin Koumouzelis and Dane Sherburn and Daniel Kappler and Daniel Levin and Daniel Levy and David Carr and David Farhi and David Mely and David Robinson and David Sasaki and Denny Jin and Dev Valladares and Dimitris Tsipras and Doug Li and Duc Phong Nguyen and Duncan Findlay and Edede Oiwoh and Edmund Wong and Ehsan Asdar and Elizabeth Proehl and Elizabeth Yang and Eric Antonow and Eric Kramer and Eric Peterson and Eric Sigler and Eric Wallace and Eugene Brevdo and Evan Mays and Farzad Khorasani and Felipe Petroski Such and Filippo Raso and Francis Zhang and Fred von Lohmann and Freddie Sulit and Gabriel Goh and Gene Oden and Geoff Salmon and Giulio Starace and Greg Brockman and Hadi Salman and Haiming Bao and Haitang Hu and Hannah Wong and Haoyu Wang and Heather Schmidt and Heather Whitney and Heewoo Jun and Hendrik Kirchner and Henrique Ponde de Oliveira Pinto and Hongyu Ren and Huiwen Chang and Hyung Won Chung and Ian Kivlichan and Ian O'Connell and Ian O'Connell and Ian Osband and Ian Silber and Ian Sohl and Ibrahim Okuyucu and Ikai Lan and Ilya Kostrikov and Ilya Sutskever and Ingmar Kanitscheider and Ishaan Gulrajani and Jacob Coxon and Jacob Menick and Jakub Pachocki and James Aung and James Betker and James Crooks and James Lennon and Jamie Kiros and Jan Leike and Jane Park and Jason Kwon and Jason Phang and Jason Teplitz and Jason Wei and Jason Wolfe and Jay Chen and Jeff Harris and Jenia Varavva and Jessica Gan Lee and Jessica Shieh and Ji Lin and Jiahui Yu and Jiayi Weng and Jie Tang and Jieqi Yu and Joanne Jang and Joaquin Quinonero Candela and Joe Beutler and Joe Landers and Joel Parish and Johannes Heidecke and John Schulman and Jonathan Lachman and Jonathan McKay and Jonathan Uesato and Jonathan Ward and Jong Wook Kim and Joost Huizinga and Jordan Sitkin and Jos Kraaijeveld and Josh Gross and Josh Kaplan and Josh Snyder and Joshua Achiam and Joy Jiao and Joyce Lee and Juntang Zhuang and Justyn Harriman and Kai Fricke and Kai Hayashi and Karan Singhal and Katy Shi and Kavin Karthik and Kayla Wood and Kendra Rimbach and Kenny Hsu and Kenny Nguyen and Keren Gu-Lemberg and Kevin Button and Kevin Liu and Kiel Howe and Krithika Muthukumar and Kyle Luther and Lama Ahmad and Larry Kai and Lauren Itow and Lauren Workman and Leher Pathak and Leo Chen and Li Jing and Lia Guy and Liam Fedus and Liang Zhou and Lien Mamitsuka and Lilian Weng and Lindsay McCallum and Lindsey Held and Long Ouyang and Louis Feuvrier and Lu Zhang and Lukas Kondraciuk and Lukasz Kaiser and Luke Hewitt and Luke Metz and Lyric Doshi and Mada Aflak and Maddie Simens and Madelaine Boyd and Madeleine Thompson and Marat Dukhan and Mark Chen and Mark Gray and Mark Hudnall and Marvin Zhang and Marwan Aljubeh and Mateusz Litwin and Matthew Zeng and Max Johnson and Maya Shetty and Mayank Gupta and Meghan Shah and Mehmet Yatbaz and Meng Jia Yang and Mengchao Zhong and Mia Glaese and Mianna Chen and Michael Janner and Michael Lampe and Michael Petrov and Michael Wu and Michele Wang and Michelle Fradin and Michelle Pokrass and Miguel Castro and Miguel Oom Temudo de Castro and Mikhail Pavlov and Miles Brundage and Miles Wang and Minal Khan and Mira Murati and Mo Bavarian and Molly Lin and Murat Yesildal and Nacho Soto and Natalia Gimelshein and Natalie Cone and Natalie Staudacher and Natalie Summers and Natan LaFontaine and Neil Chowdhury and Nick Ryder and Nick Stathas and Nick Turley and Nik Tezak and Niko Felix and Nithanth Kudige and Nitish Keskar and Noah Deutsch and Noel Bundick and Nora Puckett and Ofir Nachum and Ola Okelola and Oleg Boiko and Oleg Murk and Oliver Jaffe and Olivia Watkins and Olivier Godement and Owen Campbell-Moore and Patrick Chao and Paul McMillan and Pavel Belov and Peng Su and Peter Bak and Peter Bakkum and Peter Deng and Peter Dolan and Peter Hoeschele and Peter Welinder and Phil Tillet and Philip Pronin and Philippe Tillet and Prafulla Dhariwal and Qiming Yuan and Rachel Dias and Rachel Lim and Rahul Arora and Rajan Troll and Randall Lin and Rapha Gontijo Lopes and Raul Puri and Reah Miyara and Reimar Leike and Renaud Gaubert and Reza Zamani and Ricky Wang and Rob Donnelly and Rob Honsby and Rocky Smith and Rohan Sahai and Rohit Ramchandani and Romain Huet and Rory Carmichael and Rowan Zellers and Roy Chen and Ruby Chen and Ruslan Nigmatullin and Ryan Cheu and Saachi Jain and Sam Altman and Sam Schoenholz and Sam Toizer and Samuel Miserendino and Sandhini Agarwal and Sara Culver and Scott Ethersmith and Scott Gray and Sean Grove and Sean Metzger and Shamez Hermani and Shantanu Jain and Shengjia Zhao and Sherwin Wu and Shino Jomoto and Shirong Wu and Shuaiqi and Xia and Sonia Phene and Spencer Papay and Srinivas Narayanan and Steve Coffey and Steve Lee and Stewart Hall and Suchir Balaji and Tal Broda and Tal Stramer and Tao Xu and Tarun Gogineni and Taya Christianson and Ted Sanders and Tejal Patwardhan and Thomas Cunninghman and Thomas Degry and Thomas Dimson and Thomas Raoux and Thomas Shadwell and Tianhao Zheng and Todd Underwood and Todor Markov and Toki Sherbakov and Tom Rubin and Tom Stasi and Tomer Kaftan and Tristan Heywood and Troy Peterson and Tyce Walters and Tyna Eloundou and Valerie Qi and Veit Moeller and Vinnie Monaco and Vishal Kuo and Vlad Fomenko and Wayne Chang and Weiyi Zheng and Wenda Zhou and Wesam Manassra and Will Sheu and Wojciech Zaremba and Yash Patil and Yilei Qian and Yongjik Kim and Youlong Cheng and Yu Zhang and Yuchen He and Yuchen Zhang and Yujia Jin and Yunxing Dai and Yury Malkov},
    year={2024},
    eprint={2410.21276},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}

@misc{openai2024openai,
    title={OpenAI o1 System Card},
    author={OpenAI and : and Aaron Jaech and Adam Kalai and Adam Lerer and Adam Richardson and Ahmed El-Kishky and Aiden Low and Alec Helyar and Aleksander Madry and Alex Beutel and Alex Carney and Alex Iftimie and Alex Karpenko and Alex Tachard Passos and Alexander Neitz and Alexander Prokofiev and Alexander Wei and Allison Tam and Ally Bennett and Ananya Kumar and Andre Saraiva and Andrea Vallone and Andrew Duberstein and Andrew Kondrich and Andrey Mishchenko and Andy Applebaum and Angela Jiang and Ashvin Nair and Barret Zoph and Behrooz Ghorbani and Ben Rossen and Benjamin Sokolowsky and Boaz Barak and Bob McGrew and Borys Minaiev and Botao Hao and Bowen Baker and Brandon Houghton and Brandon McKinzie and Brydon Eastman and Camillo Lugaresi and Cary Bassin and Cary Hudson and Chak Ming Li and Charles de Bourcy and Chelsea Voss and Chen Shen and Chong Zhang and Chris Koch and Chris Orsinger and Christopher Hesse and Claudia Fischer and Clive Chan and Dan Roberts and Daniel Kappler and Daniel Levy and Daniel Selsam and David Dohan and David Farhi and David Mely and David Robinson and Dimitris Tsipras and Doug Li and Dragos Oprica and Eben Freeman and Eddie Zhang and Edmund Wong and Elizabeth Proehl and Enoch Cheung and Eric Mitchell and Eric Wallace and Erik Ritter and Evan Mays and Fan Wang and Felipe Petroski Such and Filippo Raso and Florencia Leoni and Foivos Tsimpourlas and Francis Song and Fred von Lohmann and Freddie Sulit and Geoff Salmon and Giambattista Parascandolo and Gildas Chabot and Grace Zhao and Greg Brockman and Guillaume Leclerc and Hadi Salman and Haiming Bao and Hao Sheng and Hart Andrin and Hessam Bagherinezhad and Hongyu Ren and Hunter Lightman and Hyung Won Chung and Ian Kivlichan and Ian O'Connell and Ian Osband and Ignasi Clavera Gilaberte and Ilge Akkaya and Ilya Kostrikov and Ilya Sutskever and Irina Kofman and Jakub Pachocki and James Lennon and Jason Wei and Jean Harb and Jerry Twore and Jiacheng Feng and Jiahui Yu and Jiayi Weng and Jie Tang and Jieqi Yu and Joaquin Quiñonero Candela and Joe Palermo and Joel Parish and Johannes Heidecke and John Hallman and John Rizzo and Jonathan Gordon and Jonathan Uesato and Jonathan Ward and Joost Huizinga and Julie Wang and Kai Chen and Kai Xiao and Karan Singhal and Karina Nguyen and Karl Cobbe and Katy Shi and Kayla Wood and Kendra Rimbach and Keren Gu-Lemberg and Kevin Liu and Kevin Lu and Kevin Stone and Kevin Yu and Lama Ahmad and Lauren Yang and Leo Liu and Leon Maksin and Leyton Ho and Liam Fedus and Lilian Weng and Linden Li and Lindsay McCallum and Lindsey Held and Lorenz Kuhn and Lukas Kondraciuk and Lukasz Kaiser and Luke Metz and Madelaine Boyd and Maja Trebacz and Manas Joglekar and Mark Chen and Marko Tintor and Mason Meyer and Matt Jones and Matt Kaufer and Max Schwarzer and Meghan Shah and Mehmet Yatbaz and Melody Y. Guan and Mengyuan Xu and Mengyuan Yan and Mia Glaese and Mianna Chen and Michael Lampe and Michael Malek and Michele Wang and Michelle Fradin and Mike McClay and Mikhail Pavlov and Miles Wang and Mingxuan Wang and Mira Murati and Mo Bavarian and Mostafa Rohaninejad and Nat McAleese and Neil Chowdhury and Neil Chowdhury and Nick Ryder and Nikolas Tezak and Noam Brown and Ofir Nachum and Oleg Boiko and Oleg Murk and Olivia Watkins and Patrick Chao and Paul Ashbourne and Pavel Izmailov and Peter Zhokhov and Rachel Dias and Rahul Arora and Randall Lin and Rapha Gontijo Lopes and Raz Gaon and Reah Miyara and Reimar Leike and Renny Hwang and Rhythm Garg and Robin Brown and Roshan James and Rui Shu and Ryan Cheu and Ryan Greene and Saachi Jain and Sam Altman and Sam Toizer and Sam Toyer and Samuel Miserendino and Sandhini Agarwal and Santiago Hernandez and Sasha Baker and Scott McKinney and Scottie Yan and Shengjia Zhao and Shengli Hu and Shibani Santurkar and Shraman Ray Chaudhuri and Shuyuan Zhang and Siyuan Fu and Spencer Papay and Steph Lin and Suchir Balaji and Suvansh Sanjeev and Szymon Sidor and Tal Broda and Aidan Clark and Tao Wang and Taylor Gordon and Ted Sanders and Tejal Patwardhan and Thibault Sottiaux and Thomas Degry and Thomas Dimson and Tianhao Zheng and Timur Garipov and Tom Stasi and Trapit Bansal and Trevor Creech and Troy Peterson and Tyna Eloundou and Valerie Qi and Vineet Kosaraju and Vinnie Monaco and Vitchyr Pong and Vlad Fomenko and Weiyi Zheng and Wenda Zhou and Wes McCabe and Wojciech Zaremba and Yann Dubois and Yinghai Lu and Yining Chen and Young Cha and Yu Bai and Yuchen He and Yuchen Zhang and Yunyun Wang and Zheng Shao and Zhuohan Li},
    year={2024},
    eprint={2412.16720},
    archivePrefix={arXiv},
    primaryClass={cs.AI}
}

@misc{grattafiori2024llama3herdmodels,
      title={The Llama 3 Herd of Models}, 
      author={Aaron Grattafiori and Abhimanyu Dubey and Abhinav Jauhri and Abhinav Pandey and Abhishek Kadian and Ahmad Al-Dahle and Aiesha Letman and Akhil Mathur and Alan Schelten and Alex Vaughan and Amy Yang and Angela Fan and Anirudh Goyal and Anthony Hartshorn and Aobo Yang and Archi Mitra and Archie Sravankumar and Artem Korenev and Arthur Hinsvark and Arun Rao and Aston Zhang and Aurelien Rodriguez and Austen Gregerson and Ava Spataru and Baptiste Roziere and Bethany Biron and Binh Tang and Bobbie Chern and Charlotte Caucheteux and Chaya Nayak and Chloe Bi and Chris Marra and Chris McConnell and Christian Keller and Christophe Touret and Chunyang Wu and Corinne Wong and Cristian Canton Ferrer and Cyrus Nikolaidis and Damien Allonsius and Daniel Song and Danielle Pintz and Danny Livshits and Danny Wyatt and David Esiobu and Dhruv Choudhary and Dhruv Mahajan and Diego Garcia-Olano and Diego Perino and Dieuwke Hupkes and Egor Lakomkin and Ehab AlBadawy and Elina Lobanova and Emily Dinan and Eric Michael Smith and Filip Radenovic and Francisco Guzmán and Frank Zhang and Gabriel Synnaeve and Gabrielle Lee and Georgia Lewis Anderson and Govind Thattai and Graeme Nail and Gregoire Mialon and Guan Pang and Guillem Cucurell and Hailey Nguyen and Hannah Korevaar and Hu Xu and Hugo Touvron and Iliyan Zarov and Imanol Arrieta Ibarra and Isabel Kloumann and Ishan Misra and Ivan Evtimov and Jack Zhang and Jade Copet and Jaewon Lee and Jan Geffert and Jana Vranes and Jason Park and Jay Mahadeokar and Jeet Shah and Jelmer van der Linde and Jennifer Billock and Jenny Hong and Jenya Lee and Jeremy Fu and Jianfeng Chi and Jianyu Huang and Jiawen Liu and Jie Wang and Jiecao Yu and Joanna Bitton and Joe Spisak and Jongsoo Park and Joseph Rocca and Joshua Johnstun and Joshua Saxe and Junteng Jia and Kalyan Vasuden Alwala and Karthik Prasad and Kartikeya Upasani and Kate Plawiak and Ke Li and Kenneth Heafield and Kevin Stone and Khalid El-Arini and Krithika Iyer and Kshitiz Malik and Kuenley Chiu and Kunal Bhalla and Kushal Lakhotia and Lauren Rantala-Yeary and Laurens van der Maaten and Lawrence Chen and Liang Tan and Liz Jenkins and Louis Martin and Lovish Madaan and Lubo Malo and Lukas Blecher and Lukas Landzaat and Luke de Oliveira and Madeline Muzzi and Mahesh Pasupuleti and Mannat Singh and Manohar Paluri and Marcin Kardas and Maria Tsimpoukelli and Mathew Oldham and Mathieu Rita and Maya Pavlova and Melanie Kambadur and Mike Lewis and Min Si and Mitesh Kumar Singh and Mona Hassan and Naman Goyal and Narjes Torabi and Nikolay Bashlykov and Nikolay Bogoychev and Niladri Chatterji and Ning Zhang and Olivier Duchenne and Onur Çelebi and Patrick Alrassy and Pengchuan Zhang and Pengwei Li and Petar Vasic and Peter Weng and Prajjwal Bhargava and Pratik Dubal and Praveen Krishnan and Punit Singh Koura and Puxin Xu and Qing He and Qingxiao Dong and Ragavan Srinivasan and Raj Ganapathy and Ramon Calderer and Ricardo Silveira Cabral and Robert Stojnic and Roberta Raileanu and Rohan Maheswari and Rohit Girdhar and Rohit Patel and Romain Sauvestre and Ronnie Polidoro and Roshan Sumbaly and Ross Taylor and Ruan Silva and Rui Hou and Rui Wang and Saghar Hosseini and Sahana Chennabasappa and Sanjay Singh and Sean Bell and Seohyun Sonia Kim and Sergey Edunov and Shaoliang Nie and Sharan Narang and Sharath Raparthy and Sheng Shen and Shengye Wan and Shruti Bhosale and Shun Zhang and Simon Vandenhende and Soumya Batra and Spencer Whitman and Sten Sootla and Stephane Collot and Suchin Gururangan and Sydney Borodinsky and Tamar Herman and Tara Fowler and Tarek Sheasha and Thomas Georgiou and Thomas Scialom and Tobias Speckbacher and Todor Mihaylov and Tong Xiao and Ujjwal Karn and Vedanuj Goswami and Vibhor Gupta and Vignesh Ramanathan and Viktor Kerkez and Vincent Gonguet and Virginie Do and Vish Vogeti and Vítor Albiero and Vladan Petrovic and Weiwei Chu and Wenhan Xiong and Wenyin Fu and Whitney Meers and Xavier Martinet and Xiaodong Wang and Xiaofang Wang and Xiaoqing Ellen Tan and Xide Xia and Xinfeng Xie and Xuchao Jia and Xuewei Wang and Yaelle Goldschlag and Yashesh Gaur and Yasmine Babaei and Yi Wen and Yiwen Song and Yuchen Zhang and Yue Li and Yuning Mao and Zacharie Delpierre Coudert and Zheng Yan and Zhengxing Chen and Zoe Papakipos and Aaditya Singh and Aayushi Srivastava and Abha Jain and Adam Kelsey and Adam Shajnfeld and Adithya Gangidi and Adolfo Victoria and Ahuva Goldstand and Ajay Menon and Ajay Sharma and Alex Boesenberg and Alexei Baevski and Allie Feinstein and Amanda Kallet and Amit Sangani and Amos Teo and Anam Yunus and Andrei Lupu and Andres Alvarado and Andrew Caples and Andrew Gu and Andrew Ho and Andrew Poulton and Andrew Ryan and Ankit Ramchandani and Annie Dong and Annie Franco and Anuj Goyal and Aparajita Saraf and Arkabandhu Chowdhury and Ashley Gabriel and Ashwin Bharambe and Assaf Eisenman and Azadeh Yazdan and Beau James and Ben Maurer and Benjamin Leonhardi and Bernie Huang and Beth Loyd and Beto De Paola and Bhargavi Paranjape and Bing Liu and Bo Wu and Boyu Ni and Braden Hancock and Bram Wasti and Brandon Spence and Brani Stojkovic and Brian Gamido and Britt Montalvo and Carl Parker and Carly Burton and Catalina Mejia and Ce Liu and Changhan Wang and Changkyu Kim and Chao Zhou and Chester Hu and Ching-Hsiang Chu and Chris Cai and Chris Tindal and Christoph Feichtenhofer and Cynthia Gao and Damon Civin and Dana Beaty and Daniel Kreymer and Daniel Li and David Adkins and David Xu and Davide Testuggine and Delia David and Devi Parikh and Diana Liskovich and Didem Foss and Dingkang Wang and Duc Le and Dustin Holland and Edward Dowling and Eissa Jamil and Elaine Montgomery and Eleonora Presani and Emily Hahn and Emily Wood and Eric-Tuan Le and Erik Brinkman and Esteban Arcaute and Evan Dunbar and Evan Smothers and Fei Sun and Felix Kreuk and Feng Tian and Filippos Kokkinos and Firat Ozgenel and Francesco Caggioni and Frank Kanayet and Frank Seide and Gabriela Medina Florez and Gabriella Schwarz and Gada Badeer and Georgia Swee and Gil Halpern and Grant Herman and Grigory Sizov and Guangyi and Zhang and Guna Lakshminarayanan and Hakan Inan and Hamid Shojanazeri and Han Zou and Hannah Wang and Hanwen Zha and Haroun Habeeb and Harrison Rudolph and Helen Suk and Henry Aspegren and Hunter Goldman and Hongyuan Zhan and Ibrahim Damlaj and Igor Molybog and Igor Tufanov and Ilias Leontiadis and Irina-Elena Veliche and Itai Gat and Jake Weissman and James Geboski and James Kohli and Janice Lam and Japhet Asher and Jean-Baptiste Gaya and Jeff Marcus and Jeff Tang and Jennifer Chan and Jenny Zhen and Jeremy Reizenstein and Jeremy Teboul and Jessica Zhong and Jian Jin and Jingyi Yang and Joe Cummings and Jon Carvill and Jon Shepard and Jonathan McPhie and Jonathan Torres and Josh Ginsburg and Junjie Wang and Kai Wu and Kam Hou U and Karan Saxena and Kartikay Khandelwal and Katayoun Zand and Kathy Matosich and Kaushik Veeraraghavan and Kelly Michelena and Keqian Li and Kiran Jagadeesh and Kun Huang and Kunal Chawla and Kyle Huang and Lailin Chen and Lakshya Garg and Lavender A and Leandro Silva and Lee Bell and Lei Zhang and Liangpeng Guo and Licheng Yu and Liron Moshkovich and Luca Wehrstedt and Madian Khabsa and Manav Avalani and Manish Bhatt and Martynas Mankus and Matan Hasson and Matthew Lennie and Matthias Reso and Maxim Groshev and Maxim Naumov and Maya Lathi and Meghan Keneally and Miao Liu and Michael L. Seltzer and Michal Valko and Michelle Restrepo and Mihir Patel and Mik Vyatskov and Mikayel Samvelyan and Mike Clark and Mike Macey and Mike Wang and Miquel Jubert Hermoso and Mo Metanat and Mohammad Rastegari and Munish Bansal and Nandhini Santhanam and Natascha Parks and Natasha White and Navyata Bawa and Nayan Singhal and Nick Egebo and Nicolas Usunier and Nikhil Mehta and Nikolay Pavlovich Laptev and Ning Dong and Norman Cheng and Oleg Chernoguz and Olivia Hart and Omkar Salpekar and Ozlem Kalinli and Parkin Kent and Parth Parekh and Paul Saab and Pavan Balaji and Pedro Rittner and Philip Bontrager and Pierre Roux and Piotr Dollar and Polina Zvyagina and Prashant Ratanchandani and Pritish Yuvraj and Qian Liang and Rachad Alao and Rachel Rodriguez and Rafi Ayub and Raghotham Murthy and Raghu Nayani and Rahul Mitra and Rangaprabhu Parthasarathy and Raymond Li and Rebekkah Hogan and Robin Battey and Rocky Wang and Russ Howes and Ruty Rinott and Sachin Mehta and Sachin Siby and Sai Jayesh Bondu and Samyak Datta and Sara Chugh and Sara Hunt and Sargun Dhillon and Sasha Sidorov and Satadru Pan and Saurabh Mahajan and Saurabh Verma and Seiji Yamamoto and Sharadh Ramaswamy and Shaun Lindsay and Shaun Lindsay and Sheng Feng and Shenghao Lin and Shengxin Cindy Zha and Shishir Patil and Shiva Shankar and Shuqiang Zhang and Shuqiang Zhang and Sinong Wang and Sneha Agarwal and Soji Sajuyigbe and Soumith Chintala and Stephanie Max and Stephen Chen and Steve Kehoe and Steve Satterfield and Sudarshan Govindaprasad and Sumit Gupta and Summer Deng and Sungmin Cho and Sunny Virk and Suraj Subramanian and Sy Choudhury and Sydney Goldman and Tal Remez and Tamar Glaser and Tamara Best and Thilo Koehler and Thomas Robinson and Tianhe Li and Tianjun Zhang and Tim Matthews and Timothy Chou and Tzook Shaked and Varun Vontimitta and Victoria Ajayi and Victoria Montanez and Vijai Mohan and Vinay Satish Kumar and Vishal Mangla and Vlad Ionescu and Vlad Poenaru and Vlad Tiberiu Mihailescu and Vladimir Ivanov and Wei Li and Wenchen Wang and Wenwen Jiang and Wes Bouaziz and Will Constable and Xiaocheng Tang and Xiaojian Wu and Xiaolan Wang and Xilun Wu and Xinbo Gao and Yaniv Kleinman and Yanjun Chen and Ye Hu and Ye Jia and Ye Qi and Yenda Li and Yilin Zhang and Ying Zhang and Yossi Adi and Youngjin Nam and Yu and Wang and Yu Zhao and Yuchen Hao and Yundi Qian and Yunlu Li and Yuzi He and Zach Rait and Zachary DeVito and Zef Rosnbrick and Zhaoduo Wen and Zhenyu Yang and Zhiwei Zhao and Zhiyu Ma},
      year={2024},
      eprint={2407.21783},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2407.21783}, 
}

@misc{brown2020languagemodelsfewshotlearners,
      title={Language Models are Few-Shot Learners}, 
      author={Tom B. Brown and Benjamin Mann and Nick Ryder and Melanie Subbiah and Jared Kaplan and Prafulla Dhariwal and Arvind Neelakantan and Pranav Shyam and Girish Sastry and Amanda Askell and Sandhini Agarwal and Ariel Herbert-Voss and Gretchen Krueger and Tom Henighan and Rewon Child and Aditya Ramesh and Daniel M. Ziegler and Jeffrey Wu and Clemens Winter and Christopher Hesse and Mark Chen and Eric Sigler and Mateusz Litwin and Scott Gray and Benjamin Chess and Jack Clark and Christopher Berner and Sam McCandlish and Alec Radford and Ilya Sutskever and Dario Amodei},
      year={2020},
      eprint={2005.14165},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2005.14165}, 
}

@inproceedings{Provilkov_2020,
   title={BPE-Dropout: Simple and Effective Subword Regularization},
   url={http://dx.doi.org/10.18653/v1/2020.acl-main.170},
   DOI={10.18653/v1/2020.acl-main.170},
   booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
   publisher={Association for Computational Linguistics},
   author={Provilkov, Ivan and Emelianenko, Dmitrii and Voita, Elena},
   year={2020} }


@InProceedings{Stochastic_depth,
author="Huang, Gao
and Sun, Yu
and Liu, Zhuang
and Sedra, Daniel
and Weinberger, Kilian Q.",
editor="Leibe, Bastian
and Matas, Jiri
and Sebe, Nicu
and Welling, Max",
title="Deep Networks with Stochastic Depth",
booktitle="Computer Vision -- ECCV 2016",
year="2016",
publisher="Springer International Publishing",
address="Cham",
pages="646--661",
abstract="Very deep convolutional networks with hundreds of layers have led to significant reductions in error on competitive benchmarks. Although the unmatched expressiveness of the many layers can be highly desirable at test time, training very deep networks comes with its own set of challenges. The gradients can vanish, the forward flow often diminishes, and the training time can be painfully slow. To address these problems, we propose stochastic depth, a training procedure that enables the seemingly contradictory setup to train short networks and use deep networks at test time. We start with very deep networks but during training, for each mini-batch, randomly drop a subset of layers and bypass them with the identity function. This simple approach complements the recent success of residual networks. It reduces training time substantially and improves the test error significantly on almost all data sets that we used for evaluation. With stochastic depth we can increase the depth of residual networks even beyond 1200 layers and still yield meaningful improvements in test error (4.91 {\%} on CIFAR-10).",
isbn="978-3-319-46493-0"
}



@inproceedings{Park2019SpecAugment,
  author       = {Daniel S. Park and William Chan and Yu Zhang and Chung-Cheng Chiu and Barret Zoph and Ekin D. Cubuk and Quoc V. Le},
  title        = {SpecAugment: A Simple Data Augmentation Method for Automatic Speech Recognition},
  booktitle    = {Proc. Interspeech},
  year         = {2019},
  month        = sep,
  publisher    = {ISCA},
  doi          = {10.21437/Interspeech.2019-2680},
  url          = {http://dx.doi.org/10.21437/Interspeech.2019-2680}
}



@misc{warner2024smarter,
    title={Smarter, Better, Faster, Longer: A Modern Bidirectional Encoder for Fast, Memory Efficient, and Long Context Finetuning and Inference},
    author={Benjamin Warner and Antoine Chaffin and Benjamin Clavié and Orion Weller and Oskar Hallström and Said Taghadouini and Alexis Gallagher and Raja Biswas and Faisal Ladhak and Tom Aarsen and Nathan Cooper and Griffin Adams and Jeremy Howard and Iacopo Poli},
    year={2024},
    eprint={2412.13663},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@Article{app14052074,
AUTHOR = {Patil, Rajvardhan and Gudivada, Venkat},
TITLE = {A Review of Current Trends, Techniques, and Challenges in Large Language Models (LLMs)},
JOURNAL = {Applied Sciences},
VOLUME = {14},
YEAR = {2024},
NUMBER = {5},
ARTICLE-NUMBER = {2074},
URL = {https://www.mdpi.com/2076-3417/14/5/2074},
ISSN = {2076-3417},
ABSTRACT = {Natural language processing (NLP) has significantly transformed in the last decade, especially in the field of language modeling. Large language models (LLMs) have achieved SOTA performances on natural language understanding (NLU) and natural language generation (NLG) tasks by learning language representation in self-supervised ways. This paper provides a comprehensive survey to capture the progression of advances in language models. In this paper, we examine the different aspects of language models, which started with a few million parameters but have reached the size of a trillion in a very short time. We also look at how these LLMs transitioned from task-specific to task-independent to task-and-language-independent architectures. This paper extensively discusses different pretraining objectives, benchmarks, and transfer learning methods used in LLMs. It also examines different finetuning and in-context learning techniques used in downstream tasks. Moreover, it explores how LLMs can perform well across many domains and datasets if sufficiently trained on a large and diverse dataset. Next, it discusses how, over time, the availability of cheap computational power and large datasets have improved LLM’s capabilities and raised new challenges. As part of our study, we also inspect LLMs from the perspective of scalability to see how their performance is affected by the model’s depth, width, and data size. Lastly, we provide an empirical comparison of existing trends and techniques and a comprehensive analysis of where the field of LLM currently stands.},
DOI = {10.3390/app14052074}
}





@misc{peng2022branchformer,
    title={Branchformer: Parallel MLP-Attention Architectures to Capture Local and Global Context for Speech Recognition and Understanding},
    author={Yifan Peng and Siddharth Dalmia and Ian Lane and Shinji Watanabe},
    year={2022},
    eprint={2207.02971},
    archivePrefix={arXiv},
    primaryClass={cs.CL}
}


@inproceedings{zeyer2018improved,
  title        = {Improved Training of End-to-End Attention Models for Speech Recognition},
  author       = {Zeyer, Albert and Irie, Kazuki and Schlüter, Ralf and Ney, Hermann},
  booktitle    = {Proceedings of the Annual Conference of the International Speech Communication Association (Interspeech 2018)},
  year         = {2018},
  month        = sep,
  publisher    = {ISCA},
  doi          = {10.21437/Interspeech.2018-1616},
  url          = {https://doi.org/10.21437/Interspeech.2018-1616}
}
@misc{jang2016categorical,
    title={Categorical Reparameterization with Gumbel-Softmax},
    author={Eric Jang and Shixiang Gu and Ben Poole},
    year={2016},
    eprint={1611.01144},
    archivePrefix={arXiv},
    primaryClass={stat.ML}
}

@misc{radford2022robust,
    title={Robust Speech Recognition via Large-Scale Weak Supervision},
    author={Alec Radford and Jong Wook Kim and Tao Xu and Greg Brockman and Christine McLeavey and Ilya Sutskever},
    year={2022},
    eprint={2212.04356},
    archivePrefix={arXiv},
    primaryClass={eess.AS}
}

@misc{hendrycks2016gaussian,
    title={Gaussian Error Linear Units (GELUs)},
    author={Dan Hendrycks and Kevin Gimpel},
    year={2016},
    eprint={1606.08415},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}


@misc{raffel2019exploring,
    title={Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
    author={Colin Raffel and Noam Shazeer and Adam Roberts and Katherine Lee and Sharan Narang and Michael Matena and Yanqi Zhou and Wei Li and Peter J. Liu},
    year={2019},
    eprint={1910.10683},
    archivePrefix={arXiv},
    primaryClass={cs.LG}
}

@inproceedings{He_2019,
   title={Streaming End-to-end Speech Recognition for Mobile Devices},
   url={http://dx.doi.org/10.1109/ICASSP.2019.8682336},
   DOI={10.1109/icassp.2019.8682336},
   booktitle={ICASSP 2019 - 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
   publisher={IEEE},
   author={He, Yanzhang and Sainath, Tara N. and Prabhavalkar, Rohit and McGraw, Ian and Alvarez, Raziel and Zhao, Ding and Rybach, David and Kannan, Anjuli and Wu, Yonghui and Pang, Ruoming and Liang, Qiao and Bhatia, Deepti and Shangguan, Yuan and Li, Bo and Pundak, Golan and Sim, Khe Chai and Bagby, Tom and Chang, Shuo-yiin and Rao, Kanishka and Gruenstein, Alexander},
   year={2019},
   month=may }


@INPROCEEDINGS{8661174,
  author={Rocha, Rodrigo C. O. and Petoumenos, Pavlos and Wang, Zheng and Cole, Murray and Leather, Hugh},
  booktitle={2019 IEEE/ACM International Symposium on Code Generation and Optimization (CGO)}, 
  title={Function Merging by Sequence Alignment}, 
  year={2019},
  volume={},
  number={},
  pages={149-163},
  keywords={Merging;Production;Optimization;Benchmark testing;Bioinformatics;Performance evaluation;C++ languages;Code Size;Function Merging;IPO;LTO},
  doi={10.1109/CGO.2019.8661174}}

@inproceedings{bagby2018,
author = {Bagby, Tom and Rao, Kanishka and Sim, Khe},
year = {2018},
month = {12},
pages = {506-512},
title = {Efficient Implementation of Recurrent Neural Network Transducer in Tensorflow},
doi = {10.1109/SLT.2018.8639690}
}